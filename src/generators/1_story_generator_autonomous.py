"""
Sleepy Dull Stories - COMPLETE Server-Ready Claude Story Generator with VALIDATION SYSTEM
UPDATED: All missing methods + Smart Algorithm + Database integration + Complete 5-stage pipeline + ALL LOCAL FEATURES + VALIDATION & CORRECTION
Production-optimized with complete automation + Enhanced with all local JSON files + Story Duration Validation
FINAL VERSION: All local features integrated into server version + Auto-correction system
"""

import os
import json
import pandas as pd
import logging
from datetime import datetime
from dotenv import load_dotenv
import time
import sys
import re
import random
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import sqlite3
import shutil

# Load environment first
load_dotenv()


# Server Configuration Class
class ServerConfig:
    """Server-friendly configuration management"""

    def __init__(self):
        self.setup_paths()
        self.setup_logging()
        self.setup_claude_config()
        self.ensure_directories()

    def setup_paths(self):
        """Setup server-friendly paths"""
        # Detect current file location
        current_file = Path(__file__).resolve()

        # For server: /home/youtube-automation/channels/sleepy-dull-stories/src/generators/
        # Go up to project root
        self.project_root = current_file.parent.parent.parent

        self.paths = {
            'BASE_DIR': str(self.project_root),
            'SRC_DIR': str(current_file.parent.parent),
            'DATA_DIR': str(self.project_root / 'data'),
            'OUTPUT_DIR': str(self.project_root / 'output'),
            'LOGS_DIR': str(self.project_root / 'logs'),
            'CONFIG_DIR': str(self.project_root / 'config')
        }

        # Find topics.csv for fallback only
        self.paths['TOPIC_CSV_PATH'] = self.find_topics_csv()

        print(f"‚úÖ Server paths configured:")
        print(f"   üìÅ Project root: {self.paths['BASE_DIR']}")
        print(f"   üìÑ Topics CSV (fallback): {self.paths['TOPIC_CSV_PATH']}")

    def find_topics_csv(self):
        """Find topics.csv in multiple locations or create fallback"""
        possible_paths = [
            self.project_root / 'topics.csv',
            self.project_root / 'data' / 'topics.csv',
            Path('topics.csv'),
            Path('../data/topics.csv'),
            Path('../../topics.csv')
        ]

        for path in possible_paths:
            if path.exists():
                print(f"‚úÖ Found topics.csv: {path}")
                return str(path)

        # Create fallback CSV
        return self.create_fallback_csv()

    def create_fallback_csv(self):
        """Create fallback topics.csv for testing"""
        fallback_topics = [
            {
                "topic": "Ancient Roman Villa",
                "description": "A peaceful exploration of a Roman villa at sunset, with marble columns and gardens",
                "done": 0,
                "clickbait_title": "This Ancient Roman Secret Will Put You to Sleep Instantly",
                "font_design": "Bold Roman-style font with golden (#d4af37) and deep red accents"
            },
            {
                "topic": "Medieval Castle Library",
                "description": "A quiet evening in a medieval castle's vast library with flickering candlelight",
                "done": 0,
                "clickbait_title": "Medieval Monks' Secret Sleep Ritual (2 Hour Story)",
                "font_design": "Gothic font with warm amber colors and shadow effects"
            },
            {
                "topic": "Japanese Tea Garden",
                "description": "Serene moments in a traditional Japanese tea garden during cherry blossom season",
                "done": 0,
                "clickbait_title": "Ancient Japanese Sleep Secret Hidden in Tea Gardens",
                "font_design": "Elegant brush-style font with soft pink and gold colors"
            }
        ]

        # Create in data directory
        data_dir = Path(self.paths['DATA_DIR'])
        data_dir.mkdir(exist_ok=True)

        csv_path = data_dir / 'topics.csv'
        pd.DataFrame(fallback_topics).to_csv(csv_path, index=False)

        print(f"‚úÖ Created fallback topics.csv: {csv_path}")
        return str(csv_path)

    def setup_claude_config(self):
        """Setup Claude configuration with PROVEN SETTINGS from successful version"""
        self.claude_config = {
            "model": "claude-sonnet-4-20250514",  # ‚úÖ CLAUDE 4 - PROVEN SUCCESSFUL
            "max_tokens": 64000,  # ‚úÖ HIGH TOKEN LIMIT - PROVEN SUCCESSFUL
            "temperature": 0.7,
            "target_scenes": 40,
            "target_duration_minutes": 120,
            "target_words_per_minute": 140,
            "two_stage_approach": True,
            "character_extraction": True,
            "thumbnail_generation": True,
            "max_characters": 5,
            "test_mode": False,
            "server_mode": True,
            "youtube_optimization": True,
            "platform_metadata_export": True,
            "production_specs_detailed": True,
            "streaming_response": True,  # ‚úÖ PROVEN CRITICAL
            "long_timeout": True,  # ‚úÖ PROVEN CRITICAL
            "validation_enabled": True,  # üÜï NEW: Enable validation system
            "auto_correction": True,     # üÜï NEW: Enable auto-correction
            "target_tolerance": 0.2      # üÜï NEW: ¬±20% tolerance for word count
        }

        # Get API key
        self.api_key = self.get_claude_api_key()

    def get_claude_api_key(self):
        """Get Claude API key from multiple sources"""
        # Try different environment variable names
        api_key = (
                os.getenv('CLAUDE_API_KEY') or
                os.getenv('ANTHROPIC_API_KEY') or
                os.getenv('CLAUDE_4_API_KEY') or
                os.getenv('CLAUDE_SONNET_API_KEY')
        )

        if not api_key:
            # Check .env file
            env_files = [
                Path('.env'),
                Path('../../.env'),
                Path('../../.env'),
                self.project_root / '.env'
            ]

            for env_file in env_files:
                if env_file.exists():
                    load_dotenv(env_file)
                    api_key = os.getenv('CLAUDE_API_KEY')
                    if api_key:
                        print(f"‚úÖ API key loaded from: {env_file}")
                        break

        if not api_key:
            raise ValueError(
                "‚ùå Claude API key required!\n"
                "Set in .env file:\n"
                "CLAUDE_API_KEY=sk-ant-api03-xxxxx\n"
                "Or environment variable: CLAUDE_API_KEY"
            )

        print("‚úÖ Claude API key loaded successfully")
        return api_key

    def setup_logging(self):
        """Setup production logging"""
        logs_dir = Path(self.project_root) / 'logs' / 'generators'
        logs_dir.mkdir(parents=True, exist_ok=True)

        log_file = logs_dir / f"story_gen_{datetime.now().strftime('%Y%m%d')}.log"

        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )

        self.logger = logging.getLogger("StoryGenerator")
        self.logger.info(f"‚úÖ Logging initialized: {log_file}")

    def ensure_directories(self):
        """Ensure all required directories exist"""
        dirs_to_create = [
            'DATA_DIR', 'OUTPUT_DIR', 'LOGS_DIR', 'CONFIG_DIR'
        ]

        for dir_key in dirs_to_create:
            dir_path = Path(self.paths[dir_key])
            dir_path.mkdir(parents=True, exist_ok=True)

        print("‚úÖ All directories created/verified")


# Initialize server config
try:
    CONFIG = ServerConfig()
    print("üöÄ Server configuration loaded successfully")
except Exception as e:
    print(f"‚ùå Server configuration failed: {e}")
    sys.exit(1)

# Midjourney Content Policy Awareness for Story Generator
MIDJOURNEY_CONTENT_AWARENESS_PROMPT = """
## üé® CRITICAL: MIDJOURNEY VISUAL GENERATION CONTENT POLICY AWARENESS

These visual prompts will be processed by Midjourney AI for image generation. Midjourney has strict content filtering that automatically rejects suspicious words, causing generation failures. Choose your words carefully to avoid censorship.

### üìã MIDJOURNEY'S CONTENT FILTERING SYSTEM SENSITIVITY:

#### 1. üî¥ PROBLEMATIC WORD CATEGORIES THAT CAUSE REJECTIONS:
- **Intimacy/Privacy Words**: "intimate", "private", "personal" ‚Üí AI interprets as romantic/sexual
- **Time+Location Combos**: "late at night + chamber/room" ‚Üí Creates suspicious context
- **Religious/Cultural References**: "Hebrew", "religious texts" ‚Üí Flagged as sensitive content  
- **Abstract/Supernatural**: "mystical", "supernatural", "voices" ‚Üí Creates ambiguity
- **Physical Proximity**: "embracing", "touching", "close contact" ‚Üí Romantic interpretation
- **Private Spaces**: "bedroom", "bath", "private quarters" ‚Üí Intimate space perception

#### 2. ‚úÖ SAFE ALTERNATIVE STRATEGY FOR HIGH SUCCESS RATE:
- **Lighting**: "warm lighting" ‚úÖ NOT "intimate lighting" ‚ùå
- **Spaces**: "study room" ‚úÖ NOT "private chamber" ‚ùå  
- **Time**: "evening hours" ‚úÖ NOT "late at night" ‚ùå
- **Texts**: "ancient scrolls" ‚úÖ NOT "Hebrew texts" ‚ùå
- **Atmosphere**: "peaceful ambiance" ‚úÖ NOT "mystical atmosphere" ‚ùå
- **Activity**: "focused study" ‚úÖ NOT "personal reading" ‚ùå

#### 3. üéØ PROACTIVE SAFE WORD SELECTION MINDSET:
For every word you write, ask: "Could Midjourney misinterpret this word?"
- If YES ‚Üí Find neutral, educational, academic alternative
- If NO ‚Üí Safe to proceed

#### 4. üèõÔ∏è SAFE APPROACH FOR HISTORICAL CONTENT:
Always include these safety qualifiers:
- ‚úÖ "historical educational setting"
- ‚úÖ "classical academic atmosphere" 
- ‚úÖ "scholarly learning environment"
- ‚úÖ "period-accurate educational scene"
- ‚úÖ "warm educational lighting"
- ‚úÖ "family-friendly historical content"

#### 5. üîß MENTAL SAFETY FILTER FOR EVERY PROMPT:
Before writing any visual prompt, verify:
- "Would this create an image a parent wouldn't hesitate to show their child?"
- "Is the educational/academic nature crystal clear?"
- "Are these words objective, scientific, historical?"
- "Does this avoid any romantic, intimate, or private implications?"

### üé® GUARANTEED-SAFE VISUAL PROMPT FORMULA:
```
"[HISTORICAL_LOCATION] with [CHARACTER/SCHOLARLY_ACTIVITY], warm educational lighting, 
classical academic setting, [PERIOD_DETAILS], peaceful scholarly atmosphere, 
historical educational content, family-friendly scene"
```

### üéØ TRANSFORMATION EXAMPLES:
‚ùå RISKY: "Private study chamber late at night with scholar working intimately with Hebrew texts"
‚úÖ SAFE: "Ancient study room in evening hours with scholar focused on historical manuscripts, warm educational lighting, classical academic setting, scholarly dedication"

‚ùå RISKY: "Intimate reading nook with personal cushions" 
‚úÖ SAFE: "Quiet study corner with comfortable seating, focused learning environment"

‚ùå RISKY: "Mystical voices whispering ancient wisdom"
‚úÖ SAFE: "Echo chamber preserving ancient knowledge, architectural acoustics"

### üí° SUCCESS CHECKLIST FOR EVERY VISUAL PROMPT:
1. ‚úÖ Educational/academic tone present?
2. ‚úÖ No ambiguous/suspicious words?  
3. ‚úÖ Historical/scholarly context explicit?
4. ‚úÖ Family-friendly language throughout?
5. ‚úÖ Objective, descriptive approach maintained?
6. ‚úÖ Would pass parent approval test?

### üéØ AUTOMATION SUCCESS STRATEGY:
This content awareness ensures:
- 100% Midjourney acceptance rate
- No failed generations requiring retries  
- Consistent visual output quality
- Zero content policy violations
- Reliable automation pipeline

Apply this awareness to ALL visual descriptions, scene planning, and character descriptions.
Your word choices directly impact generation success rate.
"""

print("‚úÖ Midjourney Content Policy Awareness (English) ready for integration!")

# Import Anthropic after config
try:
    from anthropic import Anthropic
    print("‚úÖ Anthropic library imported")
except ImportError:
    print("‚ùå Anthropic library not found")
    print("Install with: pip install anthropic")
    sys.exit(1)


# üÜï NEW: Story Validation and Correction System
class StoryValidationSystem:
    """Advanced story validation and auto-correction system"""

    def __init__(self, claude_client, logger):
        self.client = claude_client
        self.logger = logger
        self.validation_log = []
        self.correction_count = 0

    def log_validation_step(self, description: str, status: str = "START", metadata: Dict = None):
        """Log validation steps"""
        entry = {
            "description": description,
            "status": status,
            "timestamp": datetime.now().isoformat(),
        }
        if metadata:
            entry.update(metadata)
        self.validation_log.append(entry)

        icon = "üîç" if status == "START" else "‚úÖ" if status == "SUCCESS" else "‚ö†Ô∏è" if status == "WARNING" else "‚ùå"
        print(f"{icon} VALIDATION: {description}")
        self.logger.info(f"VALIDATION: {description} - Status: {status}")

    def validate_stories_duration(self, stories: Dict, scene_plan: List[Dict]) -> Dict:
        """Validate story durations and identify corrections needed"""

        self.log_validation_step("Starting Story Duration Validation")

        validation_results = {
            'valid_stories': {},
            'corrections_needed': [],
            'validation_summary': {
                'total_scenes': len(scene_plan),
                'stories_provided': len(stories),
                'valid_stories': 0,
                'corrections_needed': 0,
                'missing_stories': 0
            }
        }

        target_words_per_minute = CONFIG.claude_config.get('target_words_per_minute', 140)
        tolerance = CONFIG.claude_config.get('target_tolerance', 0.2)

        missing_stories = []

        for scene in scene_plan:
            scene_id = str(scene['scene_id'])
            target_duration = scene.get('duration_minutes', 4)
            target_words = int(target_duration * target_words_per_minute)

            # Check if story exists
            if scene_id not in stories:
                missing_stories.append({
                    'scene_id': scene_id,
                    'scene_title': scene.get('title', f'Scene {scene_id}'),
                    'target_duration': target_duration,
                    'target_words': target_words
                })
                continue

            story_content = stories[scene_id]
            actual_words = len(story_content.split())

            # Calculate acceptable range
            min_words = int(target_words * (1 - tolerance))
            max_words = int(target_words * (1 + tolerance))

            # Calculate deviation percentage
            deviation = abs(actual_words - target_words) / target_words

            if min_words <= actual_words <= max_words:
                # Story is within acceptable range
                validation_results['valid_stories'][scene_id] = story_content
                validation_results['validation_summary']['valid_stories'] += 1
                self.log_validation_step(
                    f"Scene {scene_id} VALID: {actual_words} words (target: {target_words}, range: {min_words}-{max_words})",
                    "SUCCESS"
                )
            else:
                # Story needs correction
                action = 'expand' if actual_words < min_words else 'trim'
                validation_results['corrections_needed'].append({
                    'scene_id': scene_id,
                    'scene_title': scene.get('title', f'Scene {scene_id}'),
                    'current_words': actual_words,
                    'target_words': target_words,
                    'min_words': min_words,
                    'max_words': max_words,
                    'deviation_percent': round(deviation * 100, 1),
                    'action': action,
                    'target_duration': target_duration,
                    'original_story': story_content
                })
                validation_results['validation_summary']['corrections_needed'] += 1
                self.log_validation_step(
                    f"Scene {scene_id} NEEDS {action.upper()}: {actual_words} words (target: {target_words}, deviation: {deviation*100:.1f}%)",
                    "WARNING"
                )

        # Handle missing stories
        if missing_stories:
            validation_results['validation_summary']['missing_stories'] = len(missing_stories)
            validation_results['missing_stories'] = missing_stories
            for missing in missing_stories:
                self.log_validation_step(
                    f"Scene {missing['scene_id']} MISSING: Story not generated",
                    "WARNING"
                )

        # Summary
        summary = validation_results['validation_summary']
        self.log_validation_step(
            f"Validation Complete: {summary['valid_stories']} valid, {summary['corrections_needed']} need correction, {summary['missing_stories']} missing",
            "SUCCESS",
            summary
        )

        return validation_results

    def auto_correct_stories(self, validation_results: Dict, scene_plan: List[Dict]) -> Dict:
        """Automatically correct stories that need adjustment"""

        corrections_needed = validation_results.get('corrections_needed', [])
        missing_stories = validation_results.get('missing_stories', [])

        if not corrections_needed and not missing_stories:
            self.log_validation_step("No corrections needed", "SUCCESS")
            return validation_results['valid_stories']

        self.log_validation_step(f"Starting Auto-Correction: {len(corrections_needed)} corrections, {len(missing_stories)} missing stories")

        corrected_stories = validation_results['valid_stories'].copy()

        # Handle corrections first
        for correction in corrections_needed:
            try:
                corrected_story = self._correct_single_story(correction, scene_plan)
                if corrected_story:
                    corrected_stories[correction['scene_id']] = corrected_story
                    self.correction_count += 1
                    self.log_validation_step(
                        f"Scene {correction['scene_id']} corrected: {correction['action']}ed to ~{correction['target_words']} words",
                        "SUCCESS"
                    )
                else:
                    # Keep original if correction fails
                    corrected_stories[correction['scene_id']] = correction['original_story']
                    self.log_validation_step(
                        f"Scene {correction['scene_id']} correction failed, keeping original",
                        "WARNING"
                    )
            except Exception as e:
                corrected_stories[correction['scene_id']] = correction['original_story']
                self.log_validation_step(
                    f"Scene {correction['scene_id']} correction error: {str(e)}",
                    "WARNING"
                )

        # Handle missing stories
        for missing in missing_stories:
            try:
                generated_story = self._generate_missing_story(missing, scene_plan)
                if generated_story:
                    corrected_stories[missing['scene_id']] = generated_story
                    self.correction_count += 1
                    self.log_validation_step(
                        f"Scene {missing['scene_id']} generated: ~{missing['target_words']} words",
                        "SUCCESS"
                    )
                else:
                    self.log_validation_step(
                        f"Scene {missing['scene_id']} generation failed",
                        "WARNING"
                    )
            except Exception as e:
                self.log_validation_step(
                    f"Scene {missing['scene_id']} generation error: {str(e)}",
                    "WARNING"
                )

        self.log_validation_step(f"Auto-Correction Complete: {self.correction_count} stories corrected/generated", "SUCCESS")
        return corrected_stories

    def _correct_single_story(self, correction: Dict, scene_plan: List[Dict]) -> Optional[str]:
        """Correct a single story's length"""

        scene_id = correction['scene_id']
        action = correction['action']
        target_words = correction['target_words']
        current_words = correction['current_words']
        original_story = correction['original_story']

        # Get scene context
        scene_info = next((s for s in scene_plan if str(s['scene_id']) == scene_id), {})
        scene_title = scene_info.get('title', f'Scene {scene_id}')
        scene_description = scene_info.get('description', 'Historical scene')
        scene_emotion = scene_info.get('emotion', 'peaceful')
        scene_template = scene_info.get('template', 'atmospheric')

        if action == 'expand':
            prompt = f"""Expand this sleep story scene to exactly {target_words} words (currently {current_words} words).

SCENE CONTEXT:
- Scene {scene_id}: {scene_title}
- Description: {scene_description}
- Emotion: {scene_emotion}
- Template: {scene_template}
- Target: {target_words} words

ORIGINAL STORY:
{original_story}

EXPANSION REQUIREMENTS:
- Keep the EXACT same opening sentence
- Maintain the same tone, style, and emotion
- Add more sensory details and atmospheric descriptions
- Expand character interactions and emotions if characters are present
- Add more historical details and period-accurate elements
- Include more [PAUSE] markers at natural breathing points
- Target exactly {target_words} words (¬±10 words acceptable)
- Keep the story sleep-optimized with gentle pacing
- Do not change the core narrative or ending

OUTPUT FORMAT: Expanded story only, no explanations or commentary."""

        else:  # trim
            prompt = f"""Trim this sleep story scene to exactly {target_words} words (currently {current_words} words).

SCENE CONTEXT:
- Scene {scene_id}: {scene_title}
- Description: {scene_description}
- Emotion: {scene_emotion}
- Template: {scene_template}
- Target: {target_words} words

ORIGINAL STORY:
{original_story}

TRIMMING REQUIREMENTS:
- Keep the EXACT same opening sentence
- Maintain core narrative atmosphere and emotion
- Remove less essential descriptive details
- Keep all character interactions and dialogue intact
- Preserve the most important sensory elements
- Keep key [PAUSE] markers for natural flow
- Target exactly {target_words} words (¬±10 words acceptable)
- Maintain sleep-optimized pacing
- Do not change the story's main events or ending

OUTPUT FORMAT: Trimmed story only, no explanations or commentary."""

        try:
            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=4000,
                temperature=0.3,
                timeout=300,
                system=f"You are a professional story editor specializing in sleep content. Your task is to {action} the story to meet exact word count requirements while maintaining all original qualities and sleep optimization.",
                messages=[{"role": "user", "content": prompt}]
            )

            corrected_story = response.content[0].text.strip()

            # Validate the correction
            new_word_count = len(corrected_story.split())
            if abs(new_word_count - target_words) <= target_words * 0.1:  # 10% tolerance for corrections
                return corrected_story
            else:
                self.log_validation_step(
                    f"Correction validation failed: got {new_word_count} words, target {target_words}",
                    "WARNING"
                )
                return None

        except Exception as e:
            self.log_validation_step(f"Correction API call failed: {str(e)}", "WARNING")
            return None

    def _generate_missing_story(self, missing: Dict, scene_plan: List[Dict]) -> Optional[str]:
        """Generate a missing story"""

        scene_id = missing['scene_id']
        target_words = missing['target_words']
        target_duration = missing['target_duration']
        scene_title = missing['scene_title']

        # Get scene context
        scene_info = next((s for s in scene_plan if str(s['scene_id']) == scene_id), {})
        scene_description = scene_info.get('description', 'Historical scene')
        scene_emotion = scene_info.get('emotion', 'peaceful')
        scene_template = scene_info.get('template', 'atmospheric')
        scene_location = scene_info.get('location', 'Ancient setting')
        key_elements = scene_info.get('key_elements', [])
        characters_mentioned = scene_info.get('characters_mentioned', [])

        prompt = f"""Generate a complete sleep story for this missing scene.

SCENE REQUIREMENTS:
- Scene {scene_id}: {scene_title}
- Location: {scene_location}
- Description: {scene_description}
- Emotion: {scene_emotion}
- Template: {scene_template}
- Duration: {target_duration} minutes
- Target words: {target_words} words
- Key Elements: {', '.join(key_elements) if key_elements else 'Atmospheric details'}
- Characters: {', '.join(characters_mentioned) if characters_mentioned else 'Focus on atmosphere'}

STORY REQUIREMENTS:
- Create a unique, atmospheric opening (NEVER use "You find yourself")
- Present tense, second person perspective
- Rich sensory details (sight, sound, smell, touch, taste)
- [PAUSE] markers at natural breathing points
- Sleep-optimized language with gentle pacing
- Historical accuracy with authentic period details
- Target exactly {target_words} words (¬±20 words acceptable)
- Maintain {scene_emotion} emotion throughout
- Include character interactions if characters are mentioned
- End with peaceful resolution

OPENING STYLE OPTIONS (choose one):
- Environmental: "The golden light filters through..."
- Temporal: "As twilight settles over..."
- Auditory: "Soft footsteps echo in..."
- Sensory: "The gentle breeze carries..."
- Visual: "Shadows dance across..."
- Character-focused: "[Character name] pauses at..."

OUTPUT FORMAT: Complete story only, no explanations or commentary."""

        try:
            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=6000,
                temperature=0.7,
                timeout=300,
                system="You are a master storyteller specializing in sleep content. Generate atmospheric, historically accurate stories that promote peaceful sleep. Focus on rich sensory details and gentle pacing.",
                messages=[{"role": "user", "content": prompt}]
            )

            generated_story = response.content[0].text.strip()

            # Validate the generation
            new_word_count = len(generated_story.split())
            if abs(new_word_count - target_words) <= target_words * 0.2:  # 20% tolerance for new generations
                return generated_story
            else:
                self.log_validation_step(
                    f"Generation validation failed: got {new_word_count} words, target {target_words}",
                    "WARNING"
                )
                return None

        except Exception as e:
            self.log_validation_step(f"Generation API call failed: {str(e)}", "WARNING")
            return None

    def get_validation_report(self) -> Dict:
        """Get comprehensive validation report"""
        return {
            'validation_log': self.validation_log,
            'corrections_made': self.correction_count,
            'validation_enabled': CONFIG.claude_config.get('validation_enabled', False),
            'auto_correction_enabled': CONFIG.claude_config.get('auto_correction', False),
            'target_tolerance': CONFIG.claude_config.get('target_tolerance', 0.2),
            'validation_summary': {
                'total_validation_steps': len(self.validation_log),
                'corrections_applied': self.correction_count,
                'validation_success': len([log for log in self.validation_log if log['status'] == 'SUCCESS'])
            }
        }


# Database Topic Management Integration
class DatabaseTopicManager:
    """Professional topic management using existing production.db"""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.add_topic_table_to_existing_db()

    def add_topic_table_to_existing_db(self):
        """Add topic table to existing production.db"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS topics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                topic TEXT NOT NULL,
                description TEXT NOT NULL,
                clickbait_title TEXT DEFAULT '',
                font_design TEXT DEFAULT '',
                status TEXT DEFAULT 'pending',
                priority INTEGER DEFAULT 1,
                target_duration_minutes INTEGER DEFAULT 135,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                production_started_at DATETIME,
                production_completed_at DATETIME,
                scene_count INTEGER,
                total_duration_minutes REAL,
                api_calls_used INTEGER DEFAULT 0,
                total_cost REAL DEFAULT 0.0,
                output_path TEXT
            )
        ''')

        conn.commit()
        conn.close()

    def import_csv_if_needed(self, csv_path: str):
        """Import CSV topics if database is empty"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('SELECT COUNT(*) FROM topics')
        topic_count = cursor.fetchone()[0]

        if topic_count == 0 and Path(csv_path).exists():
            print("üìÑ Importing topics from CSV to database...")
            try:
                df = pd.read_csv(csv_path)
                imported_count = 0

                for _, row in df.iterrows():
                    status = 'completed' if row.get('done', 0) == 1 else 'pending'

                    cursor.execute('''
                        INSERT INTO topics (
                            topic, description, clickbait_title, font_design, status
                        ) VALUES (?, ?, ?, ?, ?)
                    ''', (
                        row['topic'],
                        row['description'],
                        row.get('clickbait_title', ''),
                        row.get('font_design', ''),
                        status
                    ))
                    imported_count += 1

                conn.commit()
                print(f"‚úÖ Imported {imported_count} topics from CSV")

                # Backup CSV
                backup_path = Path(csv_path).parent / f"topics_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                import shutil
                shutil.copy2(csv_path, backup_path)
                print(f"üìÅ CSV backed up to: {backup_path}")

            except Exception as e:
                print(f"‚ùå CSV import failed: {e}")

        conn.close()

    def get_next_pending_topic(self) -> Optional[Tuple[int, str, str, str, str]]:
        """Get next pending topic from database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            SELECT id, topic, description, clickbait_title, font_design 
            FROM topics 
            WHERE status = 'pending' 
            ORDER BY priority ASC, created_at ASC 
            LIMIT 1
        ''')

        result = cursor.fetchone()
        conn.close()

        return result if result else None

    def mark_topic_as_started(self, topic_id: int):
        """Mark topic as started in production"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            UPDATE topics 
            SET status = 'in_progress', 
                production_started_at = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
        ''', (topic_id,))

        conn.commit()
        conn.close()

    def mark_topic_as_completed(self, topic_id: int, scene_count: int,
                                total_duration: float, api_calls: int,
                                total_cost: float, output_path: str):
        """Mark topic as completed with production stats"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            UPDATE topics 
            SET status = 'completed',
                production_completed_at = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP,
                scene_count = ?,
                total_duration_minutes = ?,
                api_calls_used = ?,
                total_cost = ?,
                output_path = ?
            WHERE id = ?
        ''', (scene_count, total_duration, api_calls, total_cost, output_path, topic_id))

        conn.commit()
        conn.close()


class CharacterExtractionSystem:
    """Dynamic character extraction and analysis for any story topic"""

    def __init__(self):
        self.extraction_log = []

    def log_extraction_step(self, description: str, status: str = "START", metadata: Dict = None):
        """Log character extraction steps"""
        entry = {
            "description": description,
            "status": status,
            "timestamp": datetime.now().isoformat(),
        }
        if metadata:
            entry.update(metadata)
        self.extraction_log.append(entry)

        icon = "üîç" if status == "START" else "‚úÖ" if status == "SUCCESS" else "‚ùå"
        print(f"{icon} {description}")
        CONFIG.logger.info(f"{description} - Status: {status}")

    def calculate_character_importance(self, character_data: Dict) -> int:
        """Calculate character importance score (1-10)"""
        scene_count = len(character_data.get('scene_appearances', []))
        role = character_data.get('role', 'background')

        # Base score from scene appearances
        base_score = min(10, scene_count)

        # Role multipliers
        role_multipliers = {
            'protagonist': 1.0,
            'supporting': 0.8,
            'background': 0.6,
            'minor': 0.4
        }

        multiplier = role_multipliers.get(role, 0.5)
        final_score = int(base_score * multiplier)

        return max(1, min(10, final_score))

    def filter_top_characters(self, characters: List[Dict], max_characters: int = 5) -> List[Dict]:
        """Filter to top N most important characters"""
        # Calculate importance scores
        for char in characters:
            char['importance_score'] = self.calculate_character_importance(char)

        # Sort by importance and take top N
        sorted_chars = sorted(characters, key=lambda x: x['importance_score'], reverse=True)
        return sorted_chars[:max_characters]

    def analyze_scene_character_presence(self, scene_plan: List[Dict], characters: List[Dict]) -> Dict:
        """Analyze which characters appear in which scenes"""
        scene_character_map = {}

        for scene in scene_plan:
            scene_id = scene['scene_id']
            scene_characters = []

            # Check which characters are mentioned in this scene
            scene_text = f"{scene.get('title', '')} {scene.get('description', '')} {' '.join(scene.get('key_elements', []))}"
            scene_text_lower = scene_text.lower()

            for character in characters:
                char_name = character['name'].lower()

                # Check if character is mentioned
                if (char_name in scene_text_lower or
                        any(keyword in scene_text_lower for keyword in character.get('keywords', []))):
                    scene_characters.append({
                        'name': character['name'],
                        'role': character['role'],
                        'importance_score': character['importance_score']
                    })

            scene_character_map[str(scene_id)] = scene_characters

        return scene_character_map

    def select_thumbnail_character(self, characters: List[Dict], topic: str, description: str) -> Dict:
        """Intelligently select the best character for thumbnail or decide on atmospheric approach"""

        if not characters:
            return {
                "character_used": "None (Atmospheric focus)",
                "character_data": None,
                "reasoning": "No main characters available, using atmospheric focus"
            }

        # Score characters for thumbnail potential
        scored_characters = []

        for char in characters:
            score = 0

            # Base importance
            score += char.get('importance_score', 0) * 2

            # Role bonus
            role_bonus = {
                'protagonist': 15,
                'supporting': 10,
                'background': 5,
                'minor': 2
            }
            score += role_bonus.get(char.get('role', 'minor'), 0)

            # Visual appeal factors
            if char.get('use_in_marketing', False):
                score += 10

            if char.get('thumbnail_potential'):
                if any(keyword in char['thumbnail_potential'].lower() for keyword in
                       ['excellent', 'perfect', 'strong', 'great']):
                    score += 8
                elif any(keyword in char['thumbnail_potential'].lower() for keyword in
                         ['good', 'appealing', 'works well']):
                    score += 5

            # Scene count bonus
            scene_count = len(char.get('scene_appearances', []))
            if scene_count >= 3:
                score += 5
            elif scene_count >= 2:
                score += 3

            scored_characters.append({
                'character': char,
                'score': score
            })

        # Sort by score
        scored_characters.sort(key=lambda x: x['score'], reverse=True)

        # Decision logic
        best_char = scored_characters[0]

        if best_char['score'] >= 20:  # Strong character for thumbnail
            return {
                "character_used": best_char['character']['name'],
                "character_data": best_char['character'],
                "reasoning": f"High thumbnail score ({best_char['score']}): {best_char['character'].get('thumbnail_potential', 'Strong visual presence')}"
            }
        elif best_char['score'] >= 10:  # Moderate character
            return {
                "character_used": best_char['character']['name'],
                "character_data": best_char['character'],
                "reasoning": f"Moderate thumbnail potential ({best_char['score']}): Character has good visual appeal"
            }
        else:  # Go atmospheric
            return {
                "character_used": "None (Atmospheric focus)",
                "character_data": None,
                "reasoning": f"Best character score too low ({best_char['score']}), using atmospheric approach for better visual impact"
            }


class AutomatedStoryGenerator:
    """Complete server-ready automated story generation with VALIDATION SYSTEM + FIXED Smart Algorithm + ALL LOCAL FEATURES"""

    def __init__(self):
        """Initialize story generator for server environment"""
        self.generation_log = []
        self.api_call_count = 0
        self.total_cost = 0.0
        self.character_system = CharacterExtractionSystem()

        try:
            self.client = Anthropic(api_key=CONFIG.api_key)

            # üÜï NEW: Initialize validation system
            self.validation_system = StoryValidationSystem(self.client, CONFIG.logger)

            CONFIG.logger.info("‚úÖ Story generator with validation system initialized successfully")
            print("‚úÖ Story generator initialized with Smart Algorithm + Budget Tracking + ALL LOCAL FEATURES + VALIDATION SYSTEM")
        except Exception as e:
            CONFIG.logger.error(f"‚ùå Story generator initialization failed: {e}")
            print(f"‚ùå Story generator initialization failed: {e}")
            raise

    def log_step(self, description: str, status: str = "START", metadata: Dict = None):
        """Production logging system"""
        entry = {
            "description": description,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "api_calls": self.api_call_count,
            "total_cost": self.total_cost
        }
        if metadata:
            entry.update(metadata)
        self.generation_log.append(entry)

        icon = "üîÑ" if status == "START" else "‚úÖ" if status == "SUCCESS" else "‚ùå"
        print(f"{icon} {description} [API calls: {self.api_call_count}] [Cost: ${self.total_cost:.4f}]")
        CONFIG.logger.info(
            f"{description} - Status: {status} - API calls: {self.api_call_count} - Cost: ${self.total_cost:.4f}")

    def _generate_smart_scene_structure(self, target_duration: int = 135) -> Dict:
        """FIXED: Generate smart scene structure with random count and durations"""

        # Generate random scene count (28-45)
        scene_count = random.randint(28, 40)
        print(f"üé≤ Smart Algorithm: Generated {scene_count} scenes (random 28-40)")

        # Add variation to target duration (120-150 minutes)
        actual_target = target_duration + random.randint(-15, 15)

        # Generate emotion phases
        peaceful_end = int(scene_count * 0.3)
        curiosity_end = int(scene_count * 0.6)
        concern_end = int(scene_count * 0.8)

        # Generate scene durations based on emotion
        scene_durations = []
        total_duration = 0

        for i in range(scene_count):
            # Determine emotion
            if i < peaceful_end:
                emotion = "peaceful"
                base_range = (4, 6)
            elif i < curiosity_end:
                emotion = "curiosity"
                base_range = (3, 5)
            elif i < concern_end:
                emotion = "concern"
                base_range = (2, 4)
            else:
                emotion = "resolution"
                base_range = (4, 7)

            # Generate random duration within emotion range
            duration = random.uniform(base_range[0], base_range[1])

            # Add template modifiers
            template_idx = i % 4
            templates = ["atmospheric", "character_focused", "historical_detail", "sensory_journey"]
            template = templates[template_idx]

            # Template modifiers
            modifiers = {
                "atmospheric": 1.25,
                "character_focused": 1.0,
                "historical_detail": 0.85,
                "sensory_journey": 1.15
            }

            duration *= modifiers[template]

            # Position modifiers
            if i < scene_count * 0.15:  # Opening
                duration *= 1.1
            elif i >= scene_count * 0.85:  # Resolution
                duration *= 1.2
            elif i >= scene_count * 0.7:  # Climax
                duration *= 0.9

            # Add natural variation
            duration *= random.uniform(0.9, 1.1)

            # Ensure bounds
            duration = max(1.5, min(8.0, duration))

            scene_durations.append(round(duration, 1))
            total_duration += duration

        # Adjust to target duration
        if abs(total_duration - actual_target) > 10:
            adjustment_factor = actual_target / total_duration
            scene_durations = [round(max(1.5, min(8.0, d * adjustment_factor)), 1) for d in scene_durations]
            total_duration = sum(scene_durations)

        return {
            'scene_count': scene_count,
            'scene_durations': scene_durations,
            'target_duration': actual_target,
            'actual_duration': round(total_duration, 1),
            'duration_stats': {
                'min_scene': min(scene_durations),
                'max_scene': max(scene_durations),
                'avg_scene': round(sum(scene_durations) / len(scene_durations), 1)
            },
            'natural_variation': True
        }

    def generate_complete_story_with_characters(self, topic: str, description: str, clickbait_title: str = None,
                                                font_design: str = None) -> Dict[str, Any]:
        """
        COMPLETE 5-STAGE APPROACH WITH VALIDATION SYSTEM + FIXED SMART ALGORITHM + ALL LOCAL FEATURES:
        Stage 1: Smart Planning + Hook + Subscribe + First Half stories
        Stage 2: Remaining stories (second half)
        Stage 2.5: üÜï NEW: Validation and Auto-correction of all stories
        Stage 3: Character extraction and analysis
        Stage 4: Intelligent thumbnail generation
        Stage 5: Hook & Subscribe scene selection + Complete JSON outputs
        """

        self.log_step("Complete Story Generation with VALIDATION SYSTEM + Smart Random Durations + ALL LOCAL FEATURES")

        try:
            # STAGE 1: Smart Planning + First Half
            stage1_result = self._generate_stage1(topic, description)
            time.sleep(1)  # Server-friendly pause

            # Get scene structure from stage 1
            scene_plan = stage1_result.get('scene_plan', [])
            total_scenes = len(scene_plan)
            first_half_stories = len(stage1_result.get('stories', {}))

            print(f"üé≤ Smart Structure Generated:")
            print(f"   üìä Total scenes: {total_scenes}")
            print(f"   üìù First half: {first_half_stories} stories")
            print(f"   üìù Second half: {total_scenes - first_half_stories} stories")

            if total_scenes > 0:
                durations = [scene.get('duration_minutes', 4) for scene in scene_plan]
                print(f"   ‚è±Ô∏è Duration range: {min(durations):.1f}-{max(durations):.1f} minutes")
                print(f"   üìä Total duration: {sum(durations):.1f} minutes")

            # STAGE 2: Second Half Stories
            stage2_result = self._generate_stage2(topic, description, stage1_result)
            time.sleep(1)

            # üÜï STAGE 2.5: VALIDATION AND AUTO-CORRECTION
            if CONFIG.claude_config.get('validation_enabled', True):
                validation_result = self._validate_and_correct_stories(stage1_result, stage2_result, scene_plan)
                time.sleep(1)
            else:
                print("‚ö†Ô∏è Validation system disabled, skipping validation stage")
                validation_result = {
                    'validated_stories': {**stage1_result.get('stories', {}), **stage2_result.get('stories', {})},
                    'validation_report': {'validation_enabled': False}
                }

            # STAGE 3: Character Extraction (using validated stories)
            character_result = self._extract_characters(topic, description, stage1_result, validation_result)
            time.sleep(1)

            # STAGE 4: Intelligent Thumbnail Generation
            thumbnail_result = self._generate_intelligent_thumbnail(
                topic, description, character_result, clickbait_title, font_design
            )
            time.sleep(1)

            # STAGE 5: Hook & Subscribe Scene Selection
            hook_subscribe_result = self.generate_hook_subscribe_scenes(
                stage1_result.get('scene_plan', []),
                stage1_result.get('golden_hook', {}).get('content', ''),
                stage1_result.get('subscribe_section', {}).get('content', '')
            )

            # COMBINE: Merge all stages (using validated stories)
            combined_result = self._combine_all_stages(
                stage1_result, validation_result, character_result, thumbnail_result, hook_subscribe_result, topic,
                description
            )

            # Add smart generation + validation stats
            combined_result['generation_stats'].update({
                'smart_algorithm': True,
                'random_scene_count': total_scenes,
                'natural_duration_variation': True,
                'duration_range': f"{min(durations):.1f}-{max(durations):.1f} minutes" if durations else "N/A",
                'validation_system_enabled': CONFIG.claude_config.get('validation_enabled', True),
                'auto_correction_enabled': CONFIG.claude_config.get('auto_correction', True),
                'validation_report': validation_result.get('validation_report', {})
            })

            self.log_step("Complete Smart Generation Pipeline with Validation Finished", "SUCCESS", {
                "total_scenes": len(combined_result.get('scene_plan', [])),
                "total_stories": len(combined_result.get('stories', {})),
                "characters_extracted": len(combined_result.get('main_characters', [])),
                "thumbnail_generated": combined_result.get('generation_stats', {}).get('thumbnail_generated', False),
                "hook_subscribe_generated": combined_result.get('generation_stats', {}).get('hook_subscribe_generated', False),
                "smart_algorithm_used": True,
                "validation_enabled": CONFIG.claude_config.get('validation_enabled', True),
                "stories_corrected": validation_result.get('validation_report', {}).get('corrections_made', 0),
                "api_calls_total": self.api_call_count,
                "total_cost": self.total_cost
            })

            return combined_result

        except Exception as e:
            self.log_step("Generation Failed", "ERROR")
            CONFIG.logger.error(f"Generation failed: {e}")
            raise

    def _validate_and_correct_stories(self, stage1_result: Dict, stage2_result: Dict, scene_plan: List[Dict]) -> Dict:
        """üÜï NEW: Stage 2.5 - Validate and auto-correct all stories"""

        self.log_step("Stage 2.5: Story Validation and Auto-Correction")

        # Combine all stories from both stages
        all_stories = {}
        all_stories.update(stage1_result.get('stories', {}))
        all_stories.update(stage2_result.get('stories', {}))

        # Validate stories against scene plan
        validation_results = self.validation_system.validate_stories_duration(all_stories, scene_plan)

        # Auto-correct if enabled
        if CONFIG.claude_config.get('auto_correction', True):
            corrected_stories = self.validation_system.auto_correct_stories(validation_results, scene_plan)
        else:
            corrected_stories = validation_results['valid_stories']
            print("‚ö†Ô∏è Auto-correction disabled, using only valid stories")

        # Get validation report
        validation_report = self.validation_system.get_validation_report()

        # Update API call count (validation system makes additional calls)
        if hasattr(self.validation_system, 'correction_count'):
            # Each correction/generation is approximately 1 API call
            additional_calls = self.validation_system.correction_count
            self.api_call_count += additional_calls

            # Estimate additional cost (corrections are smaller, ~$0.01 each)
            additional_cost = additional_calls * 0.01
            self.total_cost += additional_cost

        self.log_step("Story Validation and Auto-Correction", "SUCCESS", {
            "stories_validated": len(all_stories),
            "stories_corrected": validation_report.get('corrections_made', 0),
            "final_story_count": len(corrected_stories),
            "validation_enabled": True
        })

        return {
            'validated_stories': corrected_stories,
            'validation_report': validation_report,
            'validation_results': validation_results
        }

    def _generate_stage1(self, topic: str, description: str) -> Dict[str, Any]:
        """STAGE 1: ENHANCED Smart planning with powerful prompts + first half stories"""

        # Generate smart scene structure
        visual_safety_education = MIDJOURNEY_CONTENT_AWARENESS_PROMPT
        smart_structure = self._generate_smart_scene_structure()
        total_scenes = smart_structure['scene_count']
        scene_durations = smart_structure['scene_durations']
        first_half = total_scenes // 2

        self.log_step(f"Stage 1: ENHANCED Smart Planning + First {first_half} Stories (Total: {total_scenes} scenes)")

        stage1_prompt = f"""Create the complete foundation for a 2-hour sleep story about "{topic}".

    TOPIC: {topic}
    DESCRIPTION: {description}

    SMART STORY STRUCTURE:
    - Total scenes: {total_scenes} (NATURAL VARIATION - random count 28-45)
    - Target duration: {smart_structure['target_duration']} minutes
    - Scene durations: VARIABLE (see list below)
    - First half: {first_half} scenes (this stage)
    - Second half: {total_scenes - first_half} scenes (next stage)

    SCENE DURATION PLAN:
    {', '.join([f'Scene {i + 1}: {dur}min' for i, dur in enumerate(scene_durations)])}

    STAGE 1 REQUIREMENTS:
    You must provide ALL planning elements + first {first_half} stories in complete detail.
    
    ## üé≠ KRISTIN HANNAH STORYTELLING MASTERY - COMPREHENSIVE STYLE GUIDE

    ### HANNAH'S PROVEN WRITING DNA (Based on The Nightingale, Four Winds, Great Alone):
    - WISE NARRATOR VOICE: Elderly perspective reflecting on historical trauma with life-earned wisdom
    - EMOTIONAL PRECISION LANGUAGE: "Lost. It makes it sound as if I misplaced them..." - precise corrections
    - MEMORY-DRIVEN STRUCTURE: Present tense reflection, past tense for historical events
    - FEMALE RESILIENCE FOCUS: Strength emerging from impossible circumstances
    - EXTENSIVE RESEARCH DEPTH: Period-authentic details woven naturally into narrative
    - CHARACTER-DRIVEN PLOT: Personal growth drives story, not external events
    
    ### HANNAH'S SIGNATURE TECHNIQUES:
    1. OPENING VARIETY (Rotate across stories - NEVER repeat exact formulas):
       - Wisdom opener: "If I have learned anything in [time period], it is this: [insight]"
       - Memory trigger: "I find myself thinking about [historical event/people I lost]..."
       - Generational contrast: "Today's [people] want [modern thing]. I come from [different era]..."
       - Loss reflection: "[People/things] I lost. Lost. It makes it sound as if I misplaced..."
       - Time perspective: "The past has a clarity I can no longer see in the present..."
       - Experience authority: "Having lived through [event], I know that [wisdom]..."
    
    2. SENTENCE RHYTHM MASTERY:
       - Short declarative sentences for emotional impact: "They are gone."
       - Repetitive emotional refrains: "Lost...lost...but not lost. They are gone."
       - Building emotional crescendos through repetition and pacing
       - End paragraphs with profound simple truths
       - Mix flowing descriptions with sharp emotional stops
    
    3. EMOTIONAL AUTHENTICITY PATTERNS:
       - "Grief settles into our DNA and remains forever part of us"
       - "In love we find who we want to be; in war/crisis we find who we are"
       - "I come from a quieter generation. We understand the value of forgetting"
       - Focus on unsung female heroes in historical moments
       - "Women get on with it" - practical resilience theme

    ### HANNAH'S RESEARCH-DRIVEN AUTHENTICITY:
    - Historical details from "months of research" depth (Hannah's own method)
    - Period-accurate sensory details (clothing, food, sounds, smells)
    - Authentic social customs and behavioral patterns
    - Real historical events woven naturally into personal stories
    - Environmental storytelling through historical accuracy
    
    ### NARRATIVE VOICE CONSISTENCY RULES:
    - ALWAYS elderly narrator who has "lived through" or "learned from" events
    - ALWAYS present tense for reflection, past tense for story events
    - ALWAYS focus on human moments within grand historical sweep
    - ALWAYS demonstrate how crisis reveals true character
    - ALWAYS end with wisdom earned through experience
    
    ### FORBIDDEN ELEMENTS (Ensure Claude NEVER does these):
    - Identical opening sentences across multiple stories
    - Generic historical narrative without personal emotional core
    - Modern language or concepts in historical settings
    - Rushed character development without earned emotional moments
    - Surface-level historical details without authentic research depth
    
    ## 1. GOLDEN HOOK (30 seconds, ~90 words) - KRISTIN HANNAH WISDOM OPENING
    - APPLY HANNAH'S OPENING VARIETY: Select different approach from list above for each story
    - ELDERLY NARRATOR VOICE: Must sound like someone who lived through/learned from events
    - EMOTIONAL FORESHADOWING: "Last peaceful day" theme with Hannah's bittersweet wisdom
    - DISASTER AWARENESS: Narrator knows what's coming, characters don't
    - PRECISE LANGUAGE: Use Hannah's emotional correction technique ("Lost...but not lost")
    - SLEEP TRANSITION: End with gentle invitation to witness these final peaceful hours
    - AUTHENTIC WISDOM: Sound like Hannah's narrators - lived experience, not generic knowledge
    - UNIQUE EACH TIME: Never repeat exact opening formulas across stories

    ## 2. SUBSCRIBE SECTION (30 seconds, ~70 words) 
    - Natural community invitation
    - Warm, friendly tone (not corporate)

    ## 3. COMPLETE SCENE PLAN (Exactly {total_scenes} scenes with SMART DURATIONS)
    Each scene must use the exact duration from the plan above:

    {chr(10).join([f"Scene {i + 1}: {scene_durations[i]:.1f} minutes" for i in range(total_scenes)])}

    Scene structure requirements:
    - Template rotation: atmospheric, character_focused, historical_detail, sensory_journey
    - Style rotation: observational, immersive, documentary, poetic, cinematic
    - Emotion progression: 1-30% peaceful, 31-60% curiosity, 61-80% concern, 81-100% resolution
    - Key characters mentioned in descriptions

    ## 4. FIRST {first_half} COMPLETE STORIES (Scenes 1-{first_half})
    Each story must be 300-900 words (based on scene duration) with:

    ### üé® OPENING MASTERY (CRITICAL):
    - **FORBIDDEN:** Never use "You find yourself" - this phrase is completely banned
    - **REQUIRED:** Create unique, atmospheric openings for each scene
    - **VARIETY:** Use different opening styles:
      * Environmental: "The golden light filters through..."
      * Temporal: "As twilight settles over..."
      * Auditory: "Soft footsteps echo in..."
      * Sensory: "The gentle breeze carries..."
      * Visual: "Shadows dance across..."
      * Character-focused: "[Character name] pauses at..."
      * Action-based: "The wooden door creaks open..."
      * Emotional: "A sense of peace settles..."

    ### üìù PRECISION REQUIREMENTS:
    - Present tense, second person perspective
    - Rich sensory details (sight, sound, smell, touch, taste)
    - [PAUSE] markers for TTS at natural breathing points
    - Sleep-optimized language with gentle pacing
    - Historical accuracy with authentic period details
    - Clear character interactions and development
    - Word count matched to scene duration (~150 words/minute)

    ### üéØ STORYTELLING EXCELLENCE:
    - Each opening must be completely different
    - Demonstrate mastery across multiple opening styles
    - Build atmospheric immersion from first sentence
    - Natural flow that leads listeners into peaceful sleep

    {visual_safety_education}

    ## 5. BASIC VISUAL PROMPTS (All {total_scenes} scenes)
    - Simple AI image generation prompts
    - Focus on location and atmosphere
    - Character presence noted but details added later

    ## 6. VOICE DIRECTIONS (All {total_scenes} scenes)
    - TTS guidance for each scene
    - Pace, mood, emphasis

    OUTPUT FORMAT (Complete JSON):
    {{
      "golden_hook": {{
        "content": "[90-word atmospheric opening]",
        "duration_seconds": 30,
        "voice_direction": "Gentle, mysterious but calming tone"
      }},
      "subscribe_section": {{
        "content": "[70-word community invitation]",
        "duration_seconds": 30,
        "voice_direction": "Warm, friendly conversational tone"
      }},
      "scene_plan": [
        {{
          "scene_id": 1,
          "title": "[Scene title]",
          "location": "[Historical location]", 
          "duration_minutes": {scene_durations[0] if scene_durations else 4},
          "template": "atmospheric",
          "narrative_style": "observational",
          "emotion": "peaceful",
          "sensory_focus": "sight",
          "description": "[What happens - include character names if present]",
          "key_elements": ["element1", "element2", "element3"],
          "characters_mentioned": ["character1", "character2"]
        }}
      ],
      "stories": {{
        "1": "[COMPLETE story for scene 1 with MASTERFUL unique opening]",
        "2": "[COMPLETE story for scene 2 with DIFFERENT opening style]"
      }},
      "visual_prompts": [
        {{
          "scene_number": 1,
          "title": "[Scene title]",
          "prompt": "[Basic AI image prompt]",
          "duration_minutes": {scene_durations[0] if scene_durations else 4},
          "emotion": "peaceful"
        }}
      ],
      "voice_directions": [
        {{
          "scene_number": 1,
          "title": "[Scene title]", 
          "direction": "[TTS guidance]",
          "template": "atmospheric",
          "style": "observational"
        }}
      ],
      "stage1_stats": {{
        "scenes_planned": {total_scenes},
        "stories_written": {first_half},
        "enhanced_prompts_used": true,
        "master_storytelling": true,
        "opening_variety_enforced": true,
        "total_word_count": "[calculated]",
        "characters_introduced": "[count]",
        "ready_for_stage2": true
      }}
    }}

    ## STORYTELLING EXCELLENCE CHALLENGE:
    Write {first_half} completely different, masterful stories using KRISTIN HANNAH'S PROVEN METHODS:
    - **HANNAH'S OPENING VARIETY** - Different pattern from the 6 options above for each story
    - **ELDERLY NARRATOR VOICE** - Sound like Hannah's wise, experienced narrators
    - **EMOTIONAL PRECISION** - Use Hannah's specific language patterns and corrections
    - **RESEARCH-LEVEL AUTHENTICITY** - Period details with Hannah's depth and accuracy
    - **FEMALE RESILIENCE FOCUS** - Show strength emerging from impossible circumstances
    - **DISASTER FORESHADOWING** - Narrator awareness of coming tragedy, characters' innocent hope
    - **MEMORY-DRIVEN PACING** - Present reflection, past events, building emotional crescendos
    - **SENSORY AUTHENTICITY** - Historically accurate sights, sounds, smells, textures

    Demonstrate your expertise as a MASTER STORYTELLER. SHOWCASE YOUR MASTERY with creative, unique openings for each scene. The phrase "You find yourself" is banned. Instead, craft atmospheric beginnings that vary in style and immediately immerse the reader.

    USE THE EXACT DURATIONS FROM THE PLAN ABOVE."""

        try:
            self.api_call_count += 1

            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=CONFIG.claude_config["max_tokens"],
                temperature=CONFIG.claude_config["temperature"],
                stream=True,
                timeout=1800,
                system="You are KRISTIN HANNAH - the bestselling master of historical fiction. Your writing has sold 25+ million copies worldwide. Apply your proven techniques from The Nightingale, The Four Winds, and The Great Alone. Use your signature elderly narrator voice with lived wisdom, emotional precision language, and research-authentic historical details. Each opening must use a different pattern from your repertoire - never repeat exact formulas. Focus on female resilience, disaster foreshadowing, and the bittersweet beauty of last peaceful moments. Write with the depth and authenticity that made you a global phenomenon.",                messages=[{"role": "user", "content": stage1_prompt}]
            )

            content = ""
            print("üì° Stage 1: Streaming Claude 4 response with ENHANCED PROMPTS...")
            for chunk in response:
                if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'text'):
                    content += chunk.delta.text
                    if len(content) % 5000 == 0:
                        print(f"   üìä Stage 1 ENHANCED: {len(content):,} characters...")

            print(f"‚úÖ Stage 1 ENHANCED complete: {len(content):,} characters")

            input_tokens = len(stage1_prompt) // 4
            output_tokens = len(content) // 4
            stage_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)
            self.total_cost += stage_cost

            CONFIG.logger.info(f"Stage 1 ENHANCED response length: {len(content)} characters - Cost: ${stage_cost:.4f}")

            parsed_result = self._parse_claude_response(content, "stage1")

            self.log_step("Stage 1 ENHANCED Parsing", "SUCCESS", {
                "scenes_planned": len(parsed_result.get('scene_plan', [])),
                "stories_written": len(parsed_result.get('stories', {})),
                "enhanced_prompts_used": True,
                "stage_cost": stage_cost
            })

            return parsed_result

        except Exception as e:
            self.log_step("Stage 1 ENHANCED Failed", "ERROR")
            CONFIG.logger.error(f"Stage 1 enhanced error: {e}")
            raise

    def _generate_stage2(self, topic: str, description: str, stage1_result: Dict) -> Dict[str, Any]:
        """STAGE 2: ENHANCED Remaining stories with POWERFUL PROMPTS from local version"""

        scene_plan = stage1_result.get('scene_plan', [])
        stories_written = len(stage1_result.get('stories', {}))
        total_scenes = len(scene_plan)
        remaining_scenes = total_scenes - stories_written

        if remaining_scenes <= 0:
            self.log_step("Stage 2: No remaining stories needed", "SUCCESS")
            return {"stories": {}, "stage2_stats": {"stories_written": 0, "note": "All stories completed in stage 1"}}

        self.log_step(f"Stage 2: ENHANCED {remaining_scenes} Stories with POWERFUL PROMPTS")

        remaining_scene_plan = []
        for scene in scene_plan:
            if str(scene['scene_id']) not in stage1_result.get('stories', {}):
                remaining_scene_plan.append(scene)

        if len(remaining_scene_plan) == 0:
            self.log_step("Stage 2: All stories already written", "SUCCESS")
            return {"stories": {}, "stage2_stats": {"stories_written": 0, "note": "All stories completed in stage 1"}}

        scenes_text = "\n\n".join([
            f"""SCENE {scene['scene_id']}: {scene['title']}
    Location: {scene['location']}
    Duration: {scene.get('duration_minutes', 4)} minutes
    Template: {scene['template']} | Style: {scene['narrative_style']}
    Emotion: {scene['emotion']} | Sensory Focus: {scene['sensory_focus']}
    Description: {scene['description']}
    Key Elements: {', '.join(scene.get('key_elements', []))}
    Characters: {', '.join(scene.get('characters_mentioned', []))}"""
            for scene in remaining_scene_plan
        ])

        stage2_prompt = f"""Complete the sleep story for "{topic}" by writing the remaining {remaining_scenes} stories.

    TOPIC: {topic}
    DESCRIPTION: {description}

    SCENES TO COMPLETE:
    {scenes_text}

    ## MASTER STORYTELLING REQUIREMENTS (ENHANCED FROM LOCAL VERSION):

    ## KRISTIN HANNAH STORYTELLING MASTERY (CONTINUED FROM STAGE 1):

    ### üé≠ HANNAH'S OPENING VARIETY (NEVER REPEAT EXACT FORMULAS):
    - **WISDOM CONTINUATION:** "Having witnessed [event], I learned that [insight]..."
    - **MEMORY DEEPENING:** "The image that haunts me most is [specific moment]..."
    - **GENERATIONAL WISDOM:** "Young people today cannot imagine [historical reality]..."
    - **EMOTIONAL CORRECTION:** "[Something] happened. Happened - as if it were simple fate..."
    - **TIME REFLECTION:** "Looking back, I see how [moment] contained [hidden meaning]..."
    - **EXPERIENCE AUTHORITY:** "Those who lived through [event] know [truth others don't]..."
    
    ### üé® HANNAH'S NARRATIVE VOICE CONSISTENCY:
    - **ELDERLY NARRATOR:** Continue same wise, experienced voice from Stage 1
    - **EMOTIONAL PRECISION:** Use Hannah's specific correction patterns
    - **DISASTER AWARENESS:** Narrator knows outcome, characters remain hopeful
    - **FEMALE STRENGTH:** Show resilience emerging from impossible circumstances
    - **RESEARCH AUTHENTICITY:** Period-accurate details with Hannah's depth

    ### üìù WORD COUNT PRECISION:
    - 2-3 minute scenes: 300-450 words
    - 4-5 minute scenes: 600-750 words  
    - 6-7 minute scenes: 750-1050 words
    - 8+ minute scenes: 1050+ words
    - Base rate: ~150 words per minute for sleep content

    ### üé≠ CHARACTER INTEGRATION:
    - When characters mentioned: Include meaningful interactions
    - Show character personalities through actions and dialogue
    - Build emotional connections between characters
    - Progress character arcs throughout scenes

    ### üåô SLEEP OPTIMIZATION:
    - Present tense, second person perspective
    - Rich sensory details (sight, sound, smell, touch, taste)
    - [PAUSE] markers at natural breathing points
    - Gentle pacing with flowing rhythm
    - Peaceful resolution for each scene
    - Avoid jarring or startling elements

    ### üèõÔ∏è HISTORICAL ACCURACY:
    - Research-accurate period details
    - Authentic materials, tools, and practices
    - Accurate social customs and behaviors  
    - Period-appropriate dialogue and thoughts
    - Detailed environmental descriptions

    ### üéµ NARRATIVE FLOW:
    - Smooth transitions between paragraphs
    - Varied sentence lengths for rhythm
    - Building and releasing tension gently
    - Natural conversation flow
    - Descriptive passages balanced with action

    OUTPUT FORMAT:
    {{
      "stories": {{
        "{remaining_scene_plan[0]['scene_id'] if remaining_scene_plan else 'X'}": "[COMPLETE story with MASTERFUL opening and precise word count]",
        "{remaining_scene_plan[1]['scene_id'] if len(remaining_scene_plan) > 1 else 'Y'}": "[COMPLETE story with UNIQUE opening style]"
      }},
      "stage2_stats": {{
        "stories_written": {remaining_scenes},
        "scenes_covered": "{remaining_scene_plan[0]['scene_id'] if remaining_scene_plan else 'X'}-{remaining_scene_plan[-1]['scene_id'] if remaining_scene_plan else 'Y'}",
        "enhanced_prompts_used": true,
        "master_storytelling": true,
        "opening_variety_enforced": true,
        "smart_durations": true,
        "total_word_count": "[calculated]",
        "character_development": "continued"
      }}
    }}

    ## KRISTIN HANNAH EXCELLENCE CHALLENGE:
    Continue your bestselling mastery across {remaining_scenes} stories using your proven methods:
    - **HANNAH'S OPENING VARIETY** - Different wisdom/memory/reflection pattern for each story
    - **VOICE CONSISTENCY** - Same elderly narrator from Stage 1 with lived experience
    - **EMOTIONAL AUTHENTICITY** - Your signature correction patterns and precise language
    - **HISTORICAL DEPTH** - Research-level authenticity that made your novels credible
    - **FEMALE RESILIENCE** - Continue themes of strength through impossible circumstances
    - **DISASTER FORESHADOWING** - Maintain narrator's tragic knowledge vs characters' hope
    - **CHARACTER CONTINUITY** - Develop Stage 1 characters with your trademark depth
    
    Write with the same emotional precision and historical authenticity that made The Nightingale a global phenomenon. Each opening must demonstrate your mastery while never repeating exact formulas from previous stories or Stage 1."""

        try:
            self.api_call_count += 1

            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=CONFIG.claude_config["max_tokens"],
                temperature=CONFIG.claude_config["temperature"],
                stream=True,
                timeout=1800,
                system="You are KRISTIN HANNAH continuing your masterwork. Maintain your signature elderly narrator voice and emotional precision from Stage 1. Each remaining story must use a different opening pattern from your proven repertoire. Continue the female resilience themes and disaster foreshadowing established earlier. Apply the same research-authentic historical details and memory-driven narrative structure that made your novels bestsellers. Keep character development consistent with Stage 1 while varying your opening approaches.",                messages=[{"role": "user", "content": stage2_prompt}]
            )

            content = ""
            print("üì° Stage 2: Streaming Claude 4 response with ENHANCED PROMPTS...")
            for chunk in response:
                if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'text'):
                    content += chunk.delta.text
                    if len(content) % 5000 == 0:
                        print(f"   üìä Stage 2 ENHANCED: {len(content):,} characters...")

            print(f"‚úÖ Stage 2 ENHANCED complete: {len(content):,} characters")

            input_tokens = len(stage2_prompt) // 4
            output_tokens = len(content) // 4
            stage_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)
            self.total_cost += stage_cost

            parsed_result = self._parse_claude_response(content, "stage2")

            self.log_step("Stage 2 ENHANCED Parsing", "SUCCESS", {
                "stories_written": len(parsed_result.get('stories', {})),
                "enhanced_prompts_used": True,
                "stage_cost": stage_cost
            })

            return parsed_result

        except Exception as e:
            self.log_step("Stage 2 ENHANCED Failed", "ERROR")
            CONFIG.logger.error(f"Stage 2 enhanced error: {e}")
            return {"stories": {}, "stage2_stats": {"error": str(e)}}

    def generate_hook_subscribe_scenes(self, scene_plan: List[Dict], hook_content: str, subscribe_content: str) -> Dict:
        """Generate background scenes for hook and subscribe with precise timing"""

        self.log_step("Hook & Subscribe Scene Selection")

        # Select 10 atmospheric scenes for hook (0-30s)
        hook_scenes = []
        atmospheric_scenes = [s for s in scene_plan if
                              s.get('template') == 'atmospheric' or s.get('emotion') == 'peaceful'][:10]

        for i, scene in enumerate(atmospheric_scenes):
            hook_scenes.append({
                "scene_id": scene['scene_id'],
                "scene_title": scene['title'],
                "start_time": i * 3,
                "end_time": (i * 3) + 3,
                "duration": 3,
                "visual_prompt": f"Atmospheric cinematic view of {scene['location']}, golden hour lighting, peaceful and mysterious mood",
                "timing_note": f"Display during hook seconds {i * 3}-{(i * 3) + 3}",
                "sync_importance": "HIGH - Must align with hook narration rhythm"
            })

        # Select 10 community scenes for subscribe (30-60s)
        subscribe_scenes = []
        community_scenes = [s for s in scene_plan if
                            s.get('template') == 'character_focused' or len(s.get('characters_mentioned', [])) > 0][:10]

        for i, scene in enumerate(community_scenes):
            subscribe_scenes.append({
                "scene_id": scene['scene_id'],
                "scene_title": scene['title'],
                "start_time": i * 3,
                "end_time": (i * 3) + 3,
                "duration": 3,
                "visual_prompt": f"Welcoming community view of {scene['location']}, warm lighting, inviting atmosphere",
                "timing_note": f"Display during subscribe seconds {i * 3}-{(i * 3) + 3}",
                "sync_importance": "HIGH - Must feel warm and community-building"
            })

        return {
            "hook_scenes": hook_scenes,
            "subscribe_scenes": subscribe_scenes,
            "scene_story_alignment": {
                "rule": "When story mentions scene X, immediately display scene X",
                "critical": "Scene mention = Scene display",
                "timing": "Instant visual sync with narrative"
            },
            "production_notes": {
                "hook_timing": "Use hook_scenes during golden hook narration (0-30s)",
                "subscribe_timing": "Use subscribe_scenes during subscribe request (30-60s)",
                "visual_sync": "Each scene should blend seamlessly with spoken content",
                "fallback_strategy": "If scene unavailable, use next scene in sequence"
            }
        }

    def _extract_characters(self, topic: str, description: str, stage1_result: Dict, validation_result: Dict) -> Dict[str, Any]:
        """STAGE 3: Extract main characters + YouTube optimization + REGENERATE VISUAL PROMPTS (using validated stories)"""

        self.character_system.log_extraction_step("Character Extraction and Production Optimization")

        # Use validated stories instead of raw stage results
        all_stories = validation_result.get('validated_stories', {})
        scene_plan = stage1_result.get('scene_plan', [])

        # Create character extraction prompt
        story_content = ""
        for scene_id, story in all_stories.items():
            story_content += f"Scene {scene_id}:\n{story}\n\n"

        # Add scene plan for context
        scene_context = ""
        for scene in scene_plan:
            scene_context += f"Scene {scene['scene_id']}: {scene.get('title', '')} - {scene.get('description', '')}\n"

        character_prompt = f"""Analyze the complete sleep story and create character extraction + YouTube optimization package.

TOPIC: {topic}
DESCRIPTION: {description}

STORY CONTENT (First 25000 chars):
{story_content[:25000]}

SCENE PLAN CONTEXT (First 4000 chars):
{scene_context[:4000]}

REQUIREMENTS:

## PART 1: DEEP CHARACTER EXTRACTION
- Identify maximum {CONFIG.claude_config['max_characters']} main characters
- Focus on characters that appear in multiple scenes
- Provide comprehensive character analysis for each including:
  * Physical description (for visual consistency)
  * Personality traits and voice style
  * Character arc (beginning, conflict, resolution)
  * Symbolic meaning and core function in story
  * Visual contrast and lighting preferences
  * Marketing utility for thumbnails/promotion
- Map which scenes each character appears in
- Analyze character relationships and dynamics

## PART 2: YOUTUBE OPTIMIZATION
Create complete YouTube upload package

## PART 3: PRODUCTION SPECIFICATIONS
Generate all technical requirements for full automation

OUTPUT FORMAT (Complete JSON):
{{
  "main_characters": [
    {{
      "name": "[Character name]",
      "role": "protagonist|supporting|background|minor",
      "importance_score": 0,
      "scene_appearances": [1, 3, 7, 12],
      "personality_traits": ["trait1", "trait2", "trait3"],
      "physical_description": "[Detailed visual description for consistency]",
      "visual_notes": "[Special notes for image generation and lighting]",
      "voice_style": "[How character speaks - pace, tone, emotional style]",
      "core_function": "[Character's purpose in the story - symbolic or narrative role]",
      "character_arc": {{
        "beginning": "[Character's initial state/motivation]",
        "conflict": "[Main challenge or tension character faces]",
        "ending": "[Character's resolution or transformation]"
      }},
      "symbolism": "[What this character represents thematically]",
      "visual_contrast": "[Lighting, shadow, color preferences for visual distinction]",
      "emotional_journey": "[How character's emotions evolve through scenes]",
      "use_in_marketing": true/false,
      "thumbnail_potential": "[Why this character works well in thumbnails]",
      "relationships": [
        {{"character": "other_character_name", "relationship": "detailed description", "visual_dynamic": "how they appear together"}}
      ]
    }}
  ],
  "character_relationships": [
    {{
      "char1": "Character1", 
      "char2": "Character2", 
      "relationship": "detailed relationship description",
      "emotional_dynamic": "loving|respectful|complex|protective|conflicted",
      "visual_dynamic": "how they appear together in scenes",
      "story_function": "what this relationship represents in the narrative",
      "evolution": "how relationship changes throughout story",
      "symbolic_meaning": "deeper thematic significance"
    }}
  ],
  "scene_character_mapping": {{
    "1": ["Character1"],
    "2": ["Character1", "Character2"]
  }},
  "visual_style_notes": {{
    "art_style": "[Preferred illustration style]",
    "color_palette": "[Dominant colors]",
    "mood": "[Overall visual mood]",
    "period_accuracy": "[Historical period details]"
  }},
  "youtube_optimization": {{
    "clickbait_titles": [
      "This Ancient Queen's Final Secret Will Put You to Sleep Instantly",
      "I Spent 2 Hours in Ancient Palace (Sleep Story)",
      "What Really Happened in History's Most Peaceful Night?",
      "Ancient Sleep Ritual That Actually Works",
      "The Most Relaxing Historical Story Ever Told"
    ],
    "thumbnail_concept": {{
      "main_character": "[Main character name]",
      "dramatic_scene": "[Most visually striking scene]",
      "text_overlay": "[Large, bold text for thumbnail]",
      "color_scheme": "[Eye-catching colors]",
      "emotion": "[Character emotion for maximum impact]",
      "background": "[Atmospheric background]",
      "style_notes": "[Thumbnail design specifications]"
    }},
    "video_description": {{
      "hook": "[First 125 characters - crucial for SEO]",
      "main_description": "[Full description with story overview]",
      "chapters": [
        {{"time": "0:00", "title": "Golden Hook - Enter the Palace"}},
        {{"time": "0:30", "title": "Subscribe for More Sleep Stories"}},
        {{"time": "1:00", "title": "Scene 1: The Golden Antechamber"}}
      ],
      "subscribe_cta": "[Subscribe call-to-action text]",
      "social_links": "[Links to other platforms]",
      "disclaimer": "[Sleep story disclaimer text]"
    }},
    "seo_strategy": {{
      "primary_keywords": ["sleep story", "relaxation", "insomnia help"],
      "long_tail_keywords": ["2 hour sleep story ancient", "historical bedtime story"],
      "trending_keywords": ["sleep podcast", "asmr sleep"],
      "niche_keywords": ["ancient history sleep", "palace meditation"],
      "location_keywords": ["ancient", "historical"],
      "competitor_keywords": ["jason stephenson", "michelle sanctuary"]
    }},
    "tags": [
      "sleep story", "bedtime story", "relaxation", "insomnia", "meditation",
      "history", "ancient", "palace", "asmr", "calm", "peaceful", "2 hours"
    ],
    "hashtags": [
      "#sleepstory", "#bedtimestory", "#relaxation", "#meditation", "#insomnia",
      "#history", "#ancient", "#asmr", "#deepsleep", "#calm", "#stressrelief"
    ],
    "youtube_metadata": {{
      "category": "Education",
      "default_language": "en",
      "privacy_status": "public",
      "license": "youtube",
      "embeddable": true,
      "made_for_kids": false,
      "target_audience": "adults 25-65"
    }}
  }},
  "production_specifications": {{
    "audio_production": {{
      "tts_settings": {{
        "optimal_voice": "[Best TTS voice for sleep content]",
        "speed_multiplier": 0.85,
        "pitch_adjustment": -2,
        "volume_level": 80,
        "pause_durations": {{
          "[PAUSE]": 2.0,
          "paragraph_break": 1.5,
          "scene_transition": 3.0
        }}
      }},
      "background_music": {{
        "primary_track": "[Genre appropriate for story period]",
        "volume_level": 15,
        "fade_in_duration": 2.0,
        "fade_out_duration": 3.0
      }},
      "audio_export": {{
        "format": "MP3",
        "bitrate": "192kbps", 
        "sample_rate": "44.1kHz"
      }}
    }},
    "video_assembly": {{
      "scene_timing_precision": [
        {{
          "scene_number": 1,
          "start_time": "00:01:00",
          "end_time": "00:05:03", 
          "duration_seconds": 243,
          "word_count": 580
        }}
      ],
      "video_specifications": {{
        "resolution": "1920x1080",
        "frame_rate": 30,
        "transition_type": "slow_fade",
        "export_format": "MP4_H264"
      }}
    }},
    "quality_control": {{
      "content_validation": {{
        "sleep_optimization_score": "[1-10 rating]",
        "historical_accuracy_verified": true,
        "content_appropriateness": "family_friendly"
      }},
      "technical_validation": {{
        "total_word_count": "[exact count]",
        "target_duration_met": true,
        "character_consistency_score": "[1-10]"
      }}
    }}
  }},
  "character_stats": {{
    "total_characters_found": 0,
    "main_characters_extracted": 0,
    "character_coverage": "percentage of scenes with characters"
  }}
}}

Analyze thoroughly and create complete package with DEEP CHARACTER ANALYSIS including:
- Character arcs (beginning ‚Üí conflict ‚Üí resolution)
- Symbolic meaning and thematic representation  
- Visual contrast and lighting preferences
- Voice style and emotional journey
- Marketing and thumbnail potential
- Complex relationship dynamics

Plus full YouTube optimization and production specifications."""

        try:
            self.api_call_count += 1

            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=16000,
                temperature=0.3,
                stream=True,
                timeout=900,
                system="You are analyzing stories written in KRISTIN HANNAH's style. Focus on Hannah's signature female characters - resilient women who discover strength through crisis. Look for characters with Hannah's trademark emotional depth, authentic historical context, and the kind of compelling personal journeys that made The Nightingale and The Four Winds bestsellers. Extract characters who embody Hannah's themes of survival, sacrifice, and the untold stories of women in history.",                messages=[{"role": "user", "content": character_prompt}]
            )

            # Collect streaming response
            content = ""
            print("üì° Stage 3: Analyzing characters and creating optimization...")
            for chunk in response:
                if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'text'):
                    content += chunk.delta.text

            print(f"‚úÖ Character analysis complete: {len(content):,} characters")

            # Calculate cost
            input_tokens = len(character_prompt) // 4
            output_tokens = len(content) // 4
            stage_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)
            self.total_cost += stage_cost

            # Parse character extraction result
            parsed_result = self._parse_claude_response(content, "character_extraction")

            # Process characters through extraction system
            if 'main_characters' in parsed_result:
                # Filter to top characters
                top_characters = self.character_system.filter_top_characters(
                    parsed_result['main_characters'],
                    CONFIG.claude_config['max_characters']
                )
                parsed_result['main_characters'] = top_characters

                # Analyze scene-character presence
                scene_character_map = self.character_system.analyze_scene_character_presence(
                    stage1_result.get('scene_plan', []),
                    top_characters
                )
                parsed_result['scene_character_mapping'] = scene_character_map

                # REGENERATE VISUAL PROMPTS with correct character integration
                regenerated_visual_prompts = self._regenerate_visual_prompts_with_characters(
                    stage1_result.get('scene_plan', []),
                    top_characters,
                    scene_character_map,
                    parsed_result.get('visual_style_notes', {})
                )

                # Replace the old visual prompts with the regenerated ones
                parsed_result['regenerated_visual_prompts'] = regenerated_visual_prompts

                self.character_system.log_extraction_step("Visual Prompts Regenerated", "SUCCESS", {
                    "prompts_created": len(regenerated_visual_prompts),
                    "character_integrated_scenes": len(
                        [p for p in regenerated_visual_prompts if p.get('character_reference_needed')])
                })

            self.character_system.log_extraction_step("Character Extraction", "SUCCESS", {
                "characters_extracted": len(parsed_result.get('main_characters', [])),
                "character_names": [c.get('name', 'Unknown') for c in parsed_result.get('main_characters', [])],
                "visual_prompts_regenerated": 'regenerated_visual_prompts' in parsed_result,
                "stage_cost": stage_cost
            })

            return parsed_result

        except Exception as e:
            self.character_system.log_extraction_step("Character Extraction Failed", "ERROR")
            print(f"‚ùå Character extraction error: {e}")
            return {"main_characters": [], "character_stats": {"error": str(e)}}

    def _regenerate_visual_prompts_with_characters(self, scene_plan: List[Dict], characters: List[Dict],
                                                   scene_character_map: Dict, style_notes: Dict) -> List[Dict]:
        """Generate ENHANCED DRAMATIC visual prompts with better storytelling"""

        self.character_system.log_extraction_step("Enhanced Visual Prompts with Dramatic Storytelling")

        # Enhanced Midjourney safety awareness
        ENHANCED_PROMPT_GUIDE = """
        Create DRAMATIC, CINEMATIC visual prompts that tell visual stories.

        SAFETY RULES:
        - Never use: "intimate", "private", "mystical", "late at night"
        - Use instead: "contemplative", "personal reflection", "atmospheric", "evening hours"
        - Focus on educational/historical content
        - Show character emotions and interactions
        - Include environmental storytelling

        DRAMATIC ENHANCEMENT:
        - Show character emotions and reactions
        - Include multiple visual layers (foreground + background)
        - Add crisis elements for dramatic topics
        - Use environmental storytelling
        - Create cinematic composition
        """

        regeneration_prompt = f"""
        {ENHANCED_PROMPT_GUIDE}

        Create DRAMATICALLY ENHANCED visual prompts for historical story scenes.

        SCENE PLAN:
        {json.dumps([{
            'scene_id': s['scene_id'],
            'title': s['title'],
            'location': s['location'],
            'emotion': s['emotion'],
            'description': s['description']
        } for s in scene_plan], indent=2)}

        MAIN CHARACTERS:
        {json.dumps([{
            'name': char.get('name', ''),
            'physical_description': char.get('physical_description', ''),
            'role': char.get('role', '')
        } for char in characters], indent=2)}

        SCENE-CHARACTER MAPPING:
        {json.dumps(scene_character_map, indent=2)}

        REQUIREMENTS FOR EACH SCENE:
        1. If characters present: Show their emotions and interactions
        2. If no characters: Create atmospheric storytelling
        3. Add dramatic elements appropriate to the scene emotion
        4. Include environmental details that enhance the story
        5. Use historically accurate period details
        6. Create multiple visual layers (foreground + background activity)
        7. Show consequences and stakes when appropriate

        For CRISIS scenes (emotion: concern): Add evacuation, smoke, worried crowds
        For PEACEFUL scenes (emotion: peaceful): Add beauty, serenity, contemplation
        For RESOLUTION scenes: Add hope, determination, community

        OUTPUT FORMAT for each scene:
        {{
          "scene_number": X,
          "title": "[Scene title]",
          "location": "[Scene location]", 
          "characters_present": ["Character1"] or [],
          "character_reference_needed": true/false,
          "prompt": "[DRAMATICALLY ENHANCED prompt with storytelling]",
          "enhanced_prompt": "[Same prompt with character markers]",
          "duration_minutes": X,
          "emotion": "[Scene emotion]",
          "characters_in_scene": [
            {{
              "name": "Character Name",
              "description": "Physical description",
              "importance": X
            }}
          ]
        }}

        Create enhanced prompts that show VISUAL STORIES, not just static scenes.
        """

        try:
            self.api_call_count += 1

            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=16000,
                temperature=0.4,
                stream=True,
                timeout=900,
                system="You are a cinematic visual director. Create dramatic visual prompts that tell emotional stories with character interactions and environmental storytelling. Focus on showing consequences, emotions, and multiple visual layers.",
                messages=[{"role": "user", "content": regeneration_prompt}]
            )

            content = ""
            print("üì° Generating Enhanced Dramatic Visual Prompts...")
            for chunk in response:
                if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'text'):
                    content += chunk.delta.text

            print(f"‚úÖ Enhanced visual prompts complete: {len(content):,} characters")

            # Calculate cost
            input_tokens = len(regeneration_prompt) // 4
            output_tokens = len(content) // 4
            stage_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)
            self.total_cost += stage_cost

            try:
                content = content.strip()
                if content.startswith('```json'):
                    content = content[7:]
                elif content.startswith('```'):
                    content = content[3:]
                if content.endswith('```'):
                    content = content[:-3]
                content = content.strip()

                visual_prompts = json.loads(content)

                self.character_system.log_extraction_step("Enhanced Visual Prompts", "SUCCESS", {
                    "prompts_generated": len(visual_prompts),
                    "dramatic_enhancement": True,
                    "stage_cost": stage_cost
                })

                return visual_prompts

            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing failed, creating enhanced fallback: {e}")
                return self._create_enhanced_fallback_prompts(scene_plan, characters, scene_character_map)

        except Exception as e:
            self.character_system.log_extraction_step("Enhanced Visual Prompts Failed", "ERROR")
            print(f"‚ùå Enhanced visual prompt error: {e}")
            return self._create_enhanced_fallback_prompts(scene_plan, characters, scene_character_map)

    def _create_enhanced_fallback_prompts(self, scene_plan: List[Dict], characters: List[Dict],
                                          scene_character_map: Dict) -> List[Dict]:
        """Create enhanced fallback prompts with dramatic storytelling"""

        prompts = []

        for scene in scene_plan:
            scene_id = scene['scene_id']
            scene_characters = scene_character_map.get(str(scene_id), [])
            location = scene.get('location', 'Ancient setting')
            emotion = scene.get('emotion', 'peaceful')
            description = scene.get('description', '')
            title = scene.get('title', f"Scene {scene_id}")

            # Determine dramatic elements based on emotion
            if emotion == 'concern':
                drama_modifier = "showing worry and concern about unfolding events"
                environmental_drama = "with evacuation activity, worried crowds, and signs of crisis in background"
            elif emotion == 'resolution':
                drama_modifier = "showing determination and hope"
                environmental_drama = "with community coming together and hopeful atmosphere"
            else:  # peaceful
                drama_modifier = "in contemplative, serene poses"
                environmental_drama = "with beautiful, calming atmosphere and peaceful daily activities"

            # Character integration
            if scene_characters:
                char_names = [sc if isinstance(sc, str) else sc.get('name', '') for sc in scene_characters]
                char_list = ', '.join(char_names)

                prompt = f"Cinematic view of {location}, featuring {char_list} {drama_modifier}, {environmental_drama}, historically accurate period setting, warm atmospheric lighting, multiple visual layers showing both character emotions and environmental storytelling"
                enhanced_prompt = f"[CHARACTERS: {char_list}] {prompt}"
                char_ref_needed = True

                # Character details
                characters_in_scene = []
                for char_name in char_names:
                    full_char = next((c for c in characters if c['name'] == char_name), None)
                    if full_char:
                        characters_in_scene.append({
                            'name': char_name,
                            'description': full_char.get('physical_description', 'Period-appropriate character'),
                            'importance': full_char.get('importance_score', 5)
                        })
            else:
                prompt = f"Atmospheric cinematic view of {location} {environmental_drama}, historically accurate period setting, warm atmospheric lighting, environmental storytelling without characters"
                enhanced_prompt = f"[ATMOSPHERIC SCENE] {prompt}"
                char_ref_needed = False
                characters_in_scene = []

            prompt_data = {
                "scene_number": scene_id,
                "title": title,
                "location": location,
                "characters_present": [sc if isinstance(sc, str) else sc.get('name', '') for sc in scene_characters],
                "character_reference_needed": char_ref_needed,
                "prompt": prompt,
                "enhanced_prompt": enhanced_prompt,
                "duration_minutes": scene.get('duration_minutes', 4),
                "emotion": emotion,
                "characters_in_scene": characters_in_scene
            }

            prompts.append(prompt_data)

        return prompts

    def _generate_intelligent_thumbnail(self, topic: str, description: str, character_result: Dict,
                                        clickbait_title: str = None, font_design: str = None) -> Dict[str, Any]:
        """Generate DRAMATICALLY ENHANCED thumbnail with better storytelling and composition"""

        self.character_system.log_extraction_step("Enhanced Dramatic Thumbnail Generation")

        characters = character_result.get('main_characters', [])
        visual_style = character_result.get('visual_style_notes', {})

        # Analyze if this is a crisis topic
        topic_lower = f"{topic} {description}".lower()
        crisis_keywords = ['last day', 'fall', 'destruction', 'siege', 'fire', 'burning', 'final', 'end', 'war',
                           'battle']
        is_crisis = any(keyword in topic_lower for keyword in crisis_keywords)

        if is_crisis:
            drama_level = 8
            crisis_elements = [kw for kw in crisis_keywords if kw in topic_lower]
        else:
            drama_level = 4
            crisis_elements = []

        thumbnail_character_selection = self.character_system.select_thumbnail_character(
            characters, topic, description
        )

        if not clickbait_title:
            youtube_data = character_result.get('youtube_optimization', {})
            clickbait_titles = youtube_data.get('clickbait_titles', [])
            clickbait_title = clickbait_titles[
                0] if clickbait_titles else f"The Secret History of {topic} (2 Hour Sleep Story)"

        if not font_design:
            font_design = "Bold impact font, warm golden color (#d4af37), contrasted with deep shadows for readability"

        thumbnail_prompt = f"""Create a DRAMATICALLY ENHANCED thumbnail for "{topic}" that maximizes visual storytelling and clickability.

    TOPIC: {topic}
    DESCRIPTION: {description}
    CRISIS TOPIC: {is_crisis}
    DRAMA LEVEL: {drama_level}/10
    CRISIS ELEMENTS: {crisis_elements}

    CHARACTER SELECTION:
    {json.dumps(thumbnail_character_selection, indent=2)}

    CLICKBAIT TITLE: {clickbait_title}

    ## DRAMATIC THUMBNAIL REQUIREMENTS:

    ### üé¨ VISUAL STORYTELLING STRATEGY:
    1. Show EMOTIONAL REACTIONS and CONSEQUENCES, not just static poses
    2. Include ENVIRONMENTAL STORYTELLING (background elements that hint at the story)
    3. Use MULTIPLE VISUAL LAYERS (foreground emotions + background context)
    4. Show CHARACTER INTERACTIONS when multiple characters present
    5. Include SYMBOLIC ELEMENTS that enhance the narrative

    ### üé≠ CRISIS vs PEACEFUL APPROACH:
    {f'''
    FOR CRISIS TOPICS like "{topic}":
    - Characters showing concern, worry, or determination about historical events
    - Environmental indicators: smoke, crowds, evacuation activity, crisis symbols
    - Emotional expressions reflecting gravity of historical moment
    - Symbolic elements: burning scrolls, falling architecture, worried communities
    - Balance drama with peaceful, contemplative mood (not scary/jarring)
    ''' if is_crisis else f'''
    FOR PEACEFUL TOPICS like "{topic}":
    - Characters in warm, contemplative interactions
    - Beautiful environmental details: gardens, architecture, daily life
    - Serene expressions showing contentment or gentle focus
    - Symbolic elements: cultural artifacts, beautiful settings, community harmony
    - Emphasize beauty, tranquility, and historical richness
    '''}

    ### üéØ COMPOSITION STRATEGY (CRITICAL):
    - **Character Position**: RIGHT side of frame (60-70% from left edge)
    - **Text Space**: LEFT side (30-40%) must be CLEAR for text overlay
    - **Zoom Level**: Wide enough so character heads are NOT cropped
    - **Multiple Characters**: Show relationships and interactions when possible
    - **Background**: Environmental storytelling that enhances the narrative

    ### üí§ SLEEP CONTENT BALANCE:
    - Maintain warm, inviting color palette even in dramatic scenes
    - Focus on contemplative emotions rather than fear or terror
    - Use atmospheric lighting that suggests comfort and relaxation
    - Ensure overall mood invites peaceful sleep despite any drama

    OUTPUT FORMAT:
    {{
      "thumbnail_prompt": {{
        "scene_number": 99,
        "character_used": "{thumbnail_character_selection['character_used']}",
        "clickbait_title": "{clickbait_title}",
        "font_design": "{font_design}",
        "drama_level": {drama_level},
        "is_crisis_topic": {is_crisis},
        "prompt": "[DRAMATICALLY ENHANCED cinematic thumbnail with visual storytelling]",
        "visual_style": "[Style emphasizing emotional storytelling]",
        "character_positioning": "RIGHT side of frame (60-70% from left), heads not cropped",
        "text_overlay_strategy": "LEFT side (30-40%) clear for title text",
        "emotional_appeal": "[Specific emotion viewers should feel]",
        "environmental_storytelling": "[Background elements that enhance story]",
        "clickability_factors": ["factor1", "factor2", "factor3"],
        "sleep_content_balance": "[How it maintains peaceful mood while being engaging]",
        "symbolic_elements": ["element1", "element2"],
        "thumbnail_reasoning": "{thumbnail_character_selection['reasoning']}",
        "composition_notes": "RIGHT-positioned characters, LEFT text space, dramatic but peaceful"
      }},
      "thumbnail_alternatives": [
        {{
          "variant": "Character Focus",
          "prompt": "[Alternative with character emotions emphasized]"
        }},
        {{
          "variant": "Environmental Drama",
          "prompt": "[Alternative focusing on setting with character reactions]"
        }},
        {{
          "variant": "Symbolic Moment",
          "prompt": "[Alternative showing key story symbols]"
        }}
      ],
      "thumbnail_stats": {{
        "character_approach": "{thumbnail_character_selection['character_used']}",
        "visual_storytelling": true,
        "environmental_elements": true,
        "composition_optimized": true,
        "clickability_enhanced": true,
        "sleep_appropriate": true,
        "crisis_balanced": {is_crisis}
      }}
    }}

    CRITICAL: Create a thumbnail that tells a VISUAL STORY in one image. Show emotions, consequences, and environmental context that makes viewers want to click while maintaining sleep content appropriateness.

    For crisis topics: Show human emotional response to historical events with contemplative sadness rather than fear.
    For peaceful topics: Show beauty, warmth, and inviting historical atmosphere.
    """

        try:
            self.api_call_count += 1

            response = self.client.messages.create(
                model=CONFIG.claude_config["model"],
                max_tokens=8000,
                temperature=0.4,
                stream=True,
                timeout=600,
                system="You are a YouTube thumbnail specialist focused on visual storytelling. Create thumbnails that show emotional stories and consequences while maintaining sleep content appropriateness. Balance engaging visuals with peaceful, contemplative mood.",
                messages=[{"role": "user", "content": thumbnail_prompt}]
            )

            content = ""
            print("üì° Generating Enhanced Dramatic Thumbnail...")
            for chunk in response:
                if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'text'):
                    content += chunk.delta.text

            print(f"‚úÖ Enhanced thumbnail complete: {len(content):,} characters")

            input_tokens = len(thumbnail_prompt) // 4
            output_tokens = len(content) // 4
            stage_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)
            self.total_cost += stage_cost

            parsed_result = self._parse_claude_response(content, "thumbnail_generation")

            self.character_system.log_extraction_step("Enhanced Dramatic Thumbnail", "SUCCESS", {
                "drama_level": drama_level,
                "is_crisis_topic": is_crisis,
                "visual_storytelling": True,
                "stage_cost": stage_cost
            })

            return parsed_result

        except Exception as e:
            print(f"‚ùå Enhanced thumbnail error: {e}")

            # Enhanced fallback
            if is_crisis:
                fallback_elements = "showing concern about historical events, with environmental crisis indicators in background"
                mood = "contemplative sadness appropriate for historical drama"
            else:
                fallback_elements = "in peaceful, warm interactions"
                mood = "serene and inviting historical atmosphere"

            fallback_prompt = f"Cinematic thumbnail of {topic}, characters positioned RIGHT side of frame {fallback_elements}, historically accurate setting, warm atmospheric lighting, {mood}, LEFT side clear for text overlay, visual storytelling with multiple layers"

            return {
                "thumbnail_prompt": {
                    "scene_number": 99,
                    "character_used": "Main characters (enhanced fallback)",
                    "clickbait_title": clickbait_title,
                    "drama_level": drama_level,
                    "prompt": fallback_prompt,
                    "character_positioning": "RIGHT side, LEFT text space",
                    "visual_storytelling": "Enhanced environmental storytelling",
                    "thumbnail_reasoning": "Enhanced fallback with dramatic elements"
                },
                "thumbnail_stats": {
                    "visual_storytelling": True,
                    "enhanced_fallback": True
                }
            }

    def _combine_all_stages(self, stage1: Dict, validation_result: Dict, character_data: Dict, thumbnail_data: Dict,
                            hook_subscribe_data: Dict, topic: str, description: str) -> Dict[str, Any]:
        """Combine all five stages into final result - USING VALIDATED STORIES + REGENERATED VISUAL PROMPTS + THUMBNAIL + ALL LOCAL FEATURES"""

        self.log_step(
            "Combining All Stages with VALIDATED STORIES + Regenerated Visual Prompts + Thumbnail + Hook/Subscribe + ALL LOCAL FEATURES")

        # Use validated stories from validation system
        all_stories = validation_result.get('validated_stories', {})

        # Use REGENERATED visual prompts
        if 'regenerated_visual_prompts' in character_data:
            enhanced_visual_prompts = character_data['regenerated_visual_prompts']
            print(f"‚úÖ Using regenerated visual prompts: {len(enhanced_visual_prompts)} prompts")
        else:
            print("‚ö†Ô∏è Using fallback visual prompt enhancement")
            enhanced_visual_prompts = self._enhance_visual_prompts_with_characters(
                stage1.get('visual_prompts', []),
                character_data.get('main_characters', []),
                character_data.get('scene_character_mapping', {}),
                character_data.get('visual_style_notes', {})
            )

        # ADD THUMBNAIL TO VISUAL PROMPTS
        thumbnail_prompt = thumbnail_data.get('thumbnail_prompt', {})
        if thumbnail_prompt:
            enhanced_visual_prompts.append(thumbnail_prompt)
            print(f"‚úÖ Thumbnail added to visual prompts")

        # Generate scene chapters for YouTube
        scene_chapters = self._generate_scene_chapters(stage1.get('scene_plan', []))

        # Compile complete story text using validated stories
        complete_story = self._compile_complete_story({
            **stage1,
            'stories': all_stories
        })

        # Final result with ALL ENHANCEMENTS + ALL LOCAL FEATURES + VALIDATION SYSTEM
        result = {
            "hook_section": stage1.get("golden_hook", {}),
            "subscribe_section": stage1.get("subscribe_section", {}),
            "scene_plan": stage1.get("scene_plan", []),
            "scene_chapters": scene_chapters,
            "complete_story": complete_story,
            "visual_prompts": enhanced_visual_prompts,  # INCLUDES THUMBNAIL
            "voice_directions": stage1.get("voice_directions", []),
            "stories": all_stories,  # üÜï VALIDATED STORIES

            # CHARACTER DATA
            "main_characters": character_data.get('main_characters', []),
            "character_relationships": character_data.get('character_relationships', []),
            "scene_character_mapping": character_data.get('scene_character_mapping', {}),
            "visual_style_notes": character_data.get('visual_style_notes', {}),

            # YOUTUBE DATA
            "youtube_optimization": character_data.get('youtube_optimization', {}),

            # THUMBNAIL DATA
            "thumbnail_data": thumbnail_data,

            # HOOK & SUBSCRIBE DATA
            "hook_subscribe_scenes": hook_subscribe_data,

            # PRODUCTION DATA
            "production_specifications": character_data.get('production_specifications', {}),

            # üÜï VALIDATION DATA
            "validation_report": validation_result.get('validation_report', {}),
            "validation_results": validation_result.get('validation_results', {}),

            "generation_stats": {
                "api_calls_used": self.api_call_count,
                "total_cost": self.total_cost,
                "five_stage_approach": True,
                "smart_algorithm": True,
                "validation_system_enabled": CONFIG.claude_config.get('validation_enabled', True),
                "auto_correction_enabled": CONFIG.claude_config.get('auto_correction', True),
                "stories_validated": len(all_stories),
                "stories_corrected": validation_result.get('validation_report', {}).get('corrections_made', 0),
                "visual_prompts_regenerated": 'regenerated_visual_prompts' in character_data,
                "thumbnail_generated": bool(thumbnail_data.get('thumbnail_prompt')),
                "hook_subscribe_generated": bool(hook_subscribe_data.get('hook_scenes')),
                "youtube_optimization_generated": bool(
                    character_data.get('youtube_optimization', {}).get('clickbait_titles')),
                "production_specifications_generated": bool(
                    character_data.get('production_specifications', {}).get('audio_production')),
                "visual_prompts_with_thumbnail": len(enhanced_visual_prompts),
                "scenes_planned": len(stage1.get("scene_plan", [])),
                "stories_written": len(all_stories),
                "stage1_stories": len(stage1.get('stories', {})),
                "stage2_stories": len(all_stories) - len(stage1.get('stories', {})),
                "characters_extracted": len(character_data.get('main_characters', [])),
                "production_ready": len(all_stories) >= 25,
                "total_duration_minutes": sum(
                    scene.get('duration_minutes', 4) for scene in stage1.get("scene_plan", [])),
                "automated_production_ready": True,
                "server_optimized": True,
                "complete_pipeline": True,
                "all_local_features_integrated": True,
                "validation_and_correction_integrated": True
            },
            "generation_log": self.generation_log,
            "character_extraction_log": self.character_system.extraction_log,
            "validation_log": self.validation_system.validation_log,  # üÜï NEW
            "topic": topic,
            "description": description,
            "generated_at": datetime.now().isoformat(),
            "model_used": CONFIG.claude_config["model"],
            "enhancement_status": "complete_5_stage_pipeline_with_validation_system_smart_algorithm_and_all_optimizations_plus_all_local_features"
        }

        return result

    def _enhance_visual_prompts_with_characters(self, visual_prompts: List[Dict], characters: List[Dict],
                                                scene_character_map: Dict, style_notes: Dict) -> List[Dict]:
        """Enhanced visual prompts with character information (FALLBACK METHOD)"""
        enhanced_prompts = []

        for prompt in visual_prompts:
            scene_number = prompt.get('scene_number', 0)
            enhanced_prompt = prompt.copy()

            scene_characters = scene_character_map.get(str(scene_number), [])

            if scene_characters:
                character_refs = []
                for scene_char in scene_characters:
                    char_name = scene_char if isinstance(scene_char, str) else scene_char.get('name', '')
                    full_char = next((c for c in characters if c['name'] == char_name), None)
                    if full_char:
                        character_refs.append({
                            'name': full_char['name'],
                            'description': full_char['physical_description'],
                            'visual_notes': full_char.get('visual_notes', ''),
                            'importance': full_char['importance_score']
                        })

                enhanced_prompt['characters_in_scene'] = character_refs
                enhanced_prompt['character_reference_needed'] = True
                enhanced_prompt[
                    'enhanced_prompt'] = f"[CHARACTERS: {', '.join([c['name'] for c in character_refs])}] {prompt.get('prompt', '')}"
            else:
                enhanced_prompt['characters_in_scene'] = []
                enhanced_prompt['character_reference_needed'] = False
                enhanced_prompt['enhanced_prompt'] = f"[ATMOSPHERIC SCENE - NO CHARACTERS] {prompt.get('prompt', '')}"

            enhanced_prompt['visual_style_notes'] = style_notes
            enhanced_prompts.append(enhanced_prompt)

        return enhanced_prompts

    def _generate_scene_chapters(self, scene_plan: List[Dict]) -> List[Dict]:
        """Generate YouTube chapter markers for scenes"""
        chapters = []
        current_time = 60  # Start after hook and subscribe (60 seconds)

        for scene in scene_plan:
            duration_seconds = int(scene.get('duration_minutes', 4) * 60)

            chapters.append({
                "time": f"{current_time // 60}:{current_time % 60:02d}",
                "title": f"Scene {scene['scene_id']}: {scene.get('title', 'Unknown')}"[:100],
                "duration_seconds": duration_seconds,
                "emotion": scene.get('emotion', 'peaceful'),
                "template": scene.get('template', 'atmospheric')
            })

            current_time += duration_seconds

        return chapters

    def _compile_complete_story(self, story_data: Dict) -> str:
        """Compile all components into final story text"""
        story_parts = []

        # Golden Hook
        if "golden_hook" in story_data and story_data["golden_hook"]:
            story_parts.append("=== GOLDEN HOOK (0-30 seconds) ===")
            story_parts.append(story_data["golden_hook"].get("content", ""))
            story_parts.append("")

        # Subscribe Section
        if "subscribe_section" in story_data and story_data["subscribe_section"]:
            story_parts.append("=== SUBSCRIBE REQUEST (30-60 seconds) ===")
            story_parts.append(story_data["subscribe_section"].get("content", ""))
            story_parts.append("")

        # Main Story
        story_parts.append("=== MAIN STORY ===")
        story_parts.append("")

        # Add scenes
        scene_plan = story_data.get("scene_plan", [])
        stories = story_data.get("stories", {})

        for scene in scene_plan:
            scene_id = scene["scene_id"]
            story_content = stories.get(str(scene_id), f"[Story for scene {scene_id} - Planned but not yet written]")

            story_parts.append(f"## Scene {scene_id}: {scene['title']}")
            story_parts.append(f"Duration: {scene['duration_minutes']} minutes")
            story_parts.append(f"Voice: {scene['narrative_style']}")
            story_parts.append(f"Emotion: {scene['emotion']}")
            story_parts.append("")
            story_parts.append(story_content)
            story_parts.append("")

        return "\n".join(story_parts)

    def _parse_claude_response(self, content: str, stage: str) -> Dict[str, Any]:
        """Parse Claude response with improved error handling"""
        try:
            content = content.strip()
            if content.startswith('```json'):
                content = content[7:]
            elif content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()

            try:
                return json.loads(content)
            except json.JSONDecodeError:
                print(f"‚ö†Ô∏è {stage}: Full JSON failed, extracting partial data...")
                return self._extract_partial_json(content, stage)

        except Exception as e:
            print(f"‚ùå {stage} parsing failed: {e}")
            return {}

    def _extract_partial_json(self, content: str, stage: str) -> Dict[str, Any]:
        """Extract usable data from partial JSON"""
        result = {}

        try:
            if stage == "stage1":
                result = {
                    "golden_hook": self._extract_json_object(content, "golden_hook"),
                    "subscribe_section": self._extract_json_object(content, "subscribe_section"),
                    "scene_plan": self._extract_json_array(content, "scene_plan"),
                    "stories": self._extract_stories_dict(content),
                    "visual_prompts": self._extract_json_array(content, "visual_prompts"),
                    "voice_directions": self._extract_json_array(content, "voice_directions")
                }
            elif stage == "stage2":
                result = {
                    "stories": self._extract_stories_dict(content)
                }
            elif stage == "character_extraction":
                result = {
                    "main_characters": self._extract_json_array(content, "main_characters"),
                    "character_relationships": self._extract_json_array(content, "character_relationships"),
                    "scene_character_mapping": self._extract_json_object(content, "scene_character_mapping"),
                    "visual_style_notes": self._extract_json_object(content, "visual_style_notes"),
                    "youtube_optimization": self._extract_json_object(content, "youtube_optimization"),
                    "production_specifications": self._extract_json_object(content, "production_specifications"),
                    "character_stats": self._extract_json_object(content, "character_stats")
                }
            elif stage == "thumbnail_generation":
                result = {
                    "thumbnail_prompt": self._extract_json_object(content, "thumbnail_prompt"),
                    "thumbnail_alternatives": self._extract_json_array(content, "thumbnail_alternatives"),
                    "thumbnail_stats": self._extract_json_object(content, "thumbnail_stats")
                }

        except Exception as e:
            print(f"‚ö†Ô∏è Partial extraction error for {stage}: {e}")

        return result

    def _extract_json_object(self, content: str, key: str) -> Dict:
        """Extract a JSON object by key"""
        try:
            pattern = f'"{key}":\\s*{{[^}}]+}}'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                obj_json = match.group(0).replace(f'"{key}":', '')
                return json.loads(obj_json)
        except:
            pass
        return {}

    def _extract_json_array(self, content: str, key: str) -> List:
        """Extract a JSON array by key"""
        try:
            start = content.find(f'"{key}": [')
            if start == -1:
                return []

            bracket_count = 0
            in_array = False
            array_content = ""

            for i, char in enumerate(content[start:], start):
                if char == '[':
                    bracket_count += 1
                    in_array = True
                elif char == ']':
                    bracket_count -= 1
                    if bracket_count == 0 and in_array:
                        array_content = content[start + len(f'"{key}": ['):i]
                        break

            if array_content:
                objects = re.findall(r'{[^}]*}', array_content, re.DOTALL)
                complete_objects = []
                for obj in objects:
                    try:
                        json.loads(obj)
                        complete_objects.append(obj)
                    except:
                        break

                if complete_objects:
                    return json.loads('[' + ','.join(complete_objects) + ']')
        except:
            pass
        return []

    def _extract_stories_dict(self, content: str) -> Dict[str, str]:
        """Extract stories dictionary"""
        stories = {}
        try:
            story_pattern = r'"(\d+)":\s*"([^"]+(?:\\.[^"]*)*?)"'
            matches = re.findall(story_pattern, content)

            for story_id, story_content in matches:
                story_content = story_content.replace('\\"', '"')
                story_content = story_content.replace('\\n', '\n')
                story_content = story_content.replace('\\[PAUSE\\]', '[PAUSE]')

                if len(story_content) > 200:
                    stories[story_id] = story_content
        except Exception as e:
            print(f"Story extraction error: {e}")

        return stories


# Database-based topic functions
def get_next_topic_from_database() -> Tuple[int, str, str, str, str]:
    """Get next topic from database instead of CSV"""
    # Initialize database topic manager
    db_path = Path(CONFIG.paths['DATA_DIR']) / 'production.db'
    topic_manager = DatabaseTopicManager(str(db_path))

    # Import CSV if database is empty
    csv_path = CONFIG.paths['TOPIC_CSV_PATH']
    topic_manager.import_csv_if_needed(csv_path)

    # Get next pending topic
    result = topic_manager.get_next_pending_topic()

    if result:
        topic_id, topic, description, clickbait_title, font_design = result

        # Mark as started
        topic_manager.mark_topic_as_started(topic_id)

        CONFIG.logger.info(f"Topic selected from database: {topic}")
        print(f"‚úÖ Topic selected from database: {topic}")
        return topic_id, topic, description, clickbait_title, font_design
    else:
        raise ValueError("No pending topics found in database")


def complete_topic_in_database(topic_id: int, scene_count: int, total_duration: float,
                               api_calls: int, total_cost: float, output_path: str):
    """Mark topic as completed in database"""
    db_path = Path(CONFIG.paths['DATA_DIR']) / 'production.db'
    topic_manager = DatabaseTopicManager(str(db_path))

    topic_manager.mark_topic_as_completed(
        topic_id, scene_count, total_duration, api_calls, total_cost, output_path
    )

    CONFIG.logger.info(f"Topic {topic_id} marked as completed in database")
    print(f"‚úÖ Topic {topic_id} marked as completed in database")


def save_production_outputs(output_dir: str, result: Dict, story_topic: str, topic_id: int,
                            api_calls: int, total_cost: float):
    """Save complete production outputs - UPDATED SERVER VERSION WITH ALL LOCAL FEATURES + VALIDATION REPORT"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    saved_files = []

    try:
        # 1. Complete story text (using validated stories)
        story_path = output_path / "complete_story.txt"
        with open(story_path, "w", encoding="utf-8") as f:
            f.write(result["complete_story"])
        saved_files.append("complete_story.txt")

        # 2. Scene plan with enhanced chapters
        plan_path = output_path / "scene_plan.json"
        scene_data = {
            "scene_plan": result["scene_plan"],
            "scene_chapters": result.get("scene_chapters", []),
            "total_scenes": len(result.get("scene_plan", [])),
            "total_duration_minutes": sum(scene.get('duration_minutes', 4) for scene in result.get("scene_plan", [])),
            "smart_algorithm_used": result.get("generation_stats", {}).get("smart_algorithm", False),
            "validation_system_used": result.get("generation_stats", {}).get("validation_system_enabled", False)
        }
        with open(plan_path, "w", encoding="utf-8") as f:
            json.dump(scene_data, f, indent=2, ensure_ascii=False)
        saved_files.append("scene_plan.json")

        # 3. Visual prompts with thumbnail (INCLUDING SCENE 99)
        visual_path = output_path / "visual_generation_prompts.json"
        with open(visual_path, "w", encoding="utf-8") as f:
            json.dump(result["visual_prompts"], f, indent=2, ensure_ascii=False)
        saved_files.append("visual_generation_prompts.json")

        # 4. Voice directions for TTS
        voice_path = output_path / "voice_directions.json"
        with open(voice_path, "w", encoding="utf-8") as f:
            json.dump(result["voice_directions"], f, indent=2, ensure_ascii=False)
        saved_files.append("voice_directions.json")

        # 5. Character profiles
        character_path = output_path / "character_profiles.json"
        character_data = {
            "main_characters": result.get("main_characters", []),
            "character_relationships": result.get("character_relationships", []),
            "scene_character_mapping": result.get("scene_character_mapping", {}),
            "visual_style_notes": result.get("visual_style_notes", {}),
            "visual_generation_instructions": {
                "step1": "First generate reference images for each main character using their physical_description",
                "step2": "Then generate scene visuals using character references when characters_in_scene is not empty",
                "step3": "For atmospheric scenes (no characters), focus on setting and mood only",
                "step4": "Generate thumbnail using scene_number 99 in visual_generation_prompts.json",
                "reference_usage": "Always include relevant character reference images when generating scene visuals"
            }
        }
        with open(character_path, "w", encoding="utf-8") as f:
            json.dump(character_data, f, indent=2, ensure_ascii=False)
        saved_files.append("character_profiles.json")

        # üÜï 6. VALIDATION REPORT (NEW FILE)
        validation_report = result.get("validation_report", {})
        if validation_report and validation_report.get('validation_enabled', False):
            validation_path = output_path / "validation_report.json"
            validation_data = {
                "validation_report": validation_report,
                "validation_results": result.get("validation_results", {}),
                "validation_log": result.get("validation_log", []),
                "validation_summary": {
                    "validation_enabled": True,
                    "auto_correction_enabled": result.get("generation_stats", {}).get("auto_correction_enabled", False),
                    "stories_validated": result.get("generation_stats", {}).get("stories_validated", 0),
                    "stories_corrected": result.get("generation_stats", {}).get("stories_corrected", 0),
                    "target_tolerance": CONFIG.claude_config.get('target_tolerance', 0.2),
                    "target_words_per_minute": CONFIG.claude_config.get('target_words_per_minute', 140)
                }
            }
            with open(validation_path, "w", encoding="utf-8") as f:
                json.dump(validation_data, f, indent=2, ensure_ascii=False)
            saved_files.append("validation_report.json")

        # Rest of the files remain the same...
        # [Continue with platform_metadata.json, youtube_metadata.json, etc.]

        # Get main character for thumbnail concept
        main_characters = result.get("main_characters", [])
        main_character = main_characters[0] if main_characters else None
        main_char_name = main_character.get('name', 'Main Character') if main_character else 'Main Character'

        # Calculate duration info
        scene_plan = result.get('scene_plan', [])
        total_duration = sum(scene.get('duration_minutes', 4) for scene in scene_plan)
        total_hours = int(total_duration / 60)

        # 7. Platform metadata (FROM LOCAL VERSION - MORE COMPREHENSIVE THAN youtube_metadata.json)
        platform_path = output_path / "platform_metadata.json"
        youtube_data = result.get("youtube_optimization", {})

        # Create comprehensive platform metadata
        platform_data = {
            "video_metadata": {
                "category": "Education",
                "default_language": "en",
                "privacy_status": "public",
                "license": "youtube",
                "embeddable": True,
                "made_for_kids": False,
                "target_audience": f"adults 25-65 interested in {story_topic.lower()} and sleep content"
            },
            "title_options": youtube_data.get("clickbait_titles", [
                f"The Secret History of {story_topic} ({total_hours} Hour Sleep Story)",
                f"Ancient {story_topic} Sleep Story That Will Put You to Sleep Instantly",
                f"I Spent {total_hours} Hours in {story_topic} (Most Relaxing Story Ever)",
                f"What Really Happened in {story_topic}'s Most Peaceful Night?",
                f"{story_topic} Bedtime Story for Deep Sleep and Relaxation"
            ]),
            "description": {
                "hook": f"Experience the peaceful world of {story_topic} through the eyes of its people. A {total_hours}-hour sleep story for deep relaxation.",
                "main_description": f"""Journey back in time and experience the tranquil world of {story_topic}. This atmospheric sleep story follows the peaceful daily routines and lives of fascinating characters in {story_topic}.

Each scene is crafted to promote deep relaxation and peaceful sleep, featuring:
‚Ä¢ Gentle pacing perfect for bedtime
‚Ä¢ Rich historical details that transport you to another time
‚Ä¢ Soothing descriptions of daily life and peaceful moments
‚Ä¢ Multiple compelling characters living their stories
‚Ä¢ {total_hours} hours of continuous, calming narration

Perfect for insomnia, anxiety relief, or anyone who loves historical fiction combined with sleep meditation. Let the gentle rhythms of {story_topic} carry you into peaceful dreams.

‚ö†Ô∏è This story is designed to help you fall asleep - please don't listen while driving or operating machinery.""",
                "chapters": result.get("scene_chapters", []),
                "subscribe_cta": "üîî Subscribe for more historical sleep stories and relaxation content! New videos every week.",
                "social_links": "Follow us for more content: [Social media links]",
                "disclaimer": "This content is designed for relaxation and sleep. Please don't listen while driving or operating machinery."
            },
            "tags": youtube_data.get("tags", [
                "sleep story", "bedtime story", "relaxation", "insomnia help", "meditation",
                "calm", "peaceful", f"{total_hours} hours", "deep sleep", "anxiety relief",
                "stress relief", "asmr", "history", story_topic.lower()
            ]),
            "hashtags": youtube_data.get("hashtags", [
                "#sleepstory", "#bedtimestory", "#relaxation", "#meditation", "#insomnia",
                "#deepsleep", "#calm", "#history", f"#{story_topic.lower().replace(' ', '')}"
            ]),
            "seo_strategy": youtube_data.get("seo_strategy", {
                "primary_keywords": ["sleep story", story_topic.lower(), "bedtime story", "relaxation"],
                "long_tail_keywords": [f"{total_hours} hour sleep story {story_topic.lower()}",
                                       f"{story_topic.lower()} historical bedtime story"],
                "trending_keywords": ["sleep podcast", "historical fiction sleep", "ancient history relaxation"],
                "niche_keywords": [f"{story_topic.lower()} sleep story", f"{story_topic.lower()} meditation"],
                "location_keywords": [word.lower() for word in story_topic.split()],
                "competitor_keywords": ["jason stephenson history", "michelle sanctuary ancient"]
            }),
            "thumbnail_concept": {
                "main_character": main_char_name,
                "dramatic_scene": f"{main_char_name} in atmospheric {story_topic} setting",
                "text_overlay": youtube_data.get("clickbait_titles", [f"{story_topic.upper()}'S SECRET"])[0][
                                :20].upper() if youtube_data.get(
                    "clickbait_titles") else f"{story_topic.upper()}'S SECRET",
                "color_scheme": "Warm golds and deep blues with atmospheric lighting",
                "emotion": "Peaceful concentration and serenity",
                "background": f"Atmospheric {story_topic} setting with cinematic lighting",
                "style_notes": "Cinematic lighting, warm and inviting mood that suggests comfort and relaxation"
            },
            "engagement_strategy": youtube_data.get("engagement_strategy", {}),
            "analytics_tracking": youtube_data.get("analytics_tracking", {}),
            "api_ready_format": {
                "snippet": {
                    "title": youtube_data.get("clickbait_titles", [
                        f"The Secret History of {story_topic} ({total_hours} Hour Sleep Story)"])[
                        0] if youtube_data.get(
                        "clickbait_titles") else f"The Secret History of {story_topic} ({total_hours} Hour Sleep Story)",
                    "description": f"""Journey back in time and experience the tranquil world of {story_topic}. This atmospheric sleep story follows the peaceful daily routines and lives of fascinating characters in {story_topic}.

Each scene is crafted to promote deep relaxation and peaceful sleep, featuring:
‚Ä¢ Gentle pacing perfect for bedtime
‚Ä¢ Rich historical details that transport you to another time
‚Ä¢ Soothing descriptions of daily life and peaceful moments
‚Ä¢ Multiple compelling characters living their stories
‚Ä¢ {total_hours} hours of continuous, calming narration

Perfect for insomnia, anxiety relief, or anyone who loves historical fiction combined with sleep meditation. Let the gentle rhythms of {story_topic} carry you into peaceful dreams.

‚ö†Ô∏è This story is designed to help you fall asleep - please don't listen while driving or operating machinery.""",
                    "tags": youtube_data.get("tags", [
                        "sleep story", "bedtime story", "relaxation", "insomnia help", "meditation",
                        "calm", "peaceful", f"{total_hours} hours", "deep sleep", "anxiety relief",
                        "stress relief", "asmr", "history", story_topic.lower()
                    ])[:30],
                    "categoryId": "27",
                    "defaultLanguage": "en",
                    "defaultAudioLanguage": "en"
                },
                "status": {
                    "privacyStatus": "public",
                    "embeddable": True,
                    "license": "youtube",
                    "publicStatsViewable": True,
                    "madeForKids": False
                }
            }
        }
        with open(platform_path, "w", encoding="utf-8") as f:
            json.dump(platform_data, f, indent=2, ensure_ascii=False)
        saved_files.append("platform_metadata.json")

        # 8. YouTube metadata (SIMPLIFIED VERSION FOR BACKWARD COMPATIBILITY)
        youtube_path = output_path / "youtube_metadata.json"
        youtube_metadata = {
            "clickbait_titles": youtube_data.get("clickbait_titles", platform_data["title_options"]),
            "video_description": youtube_data.get("video_description", platform_data["description"]),
            "tags": youtube_data.get("tags", platform_data["tags"]),
            "hashtags": youtube_data.get("hashtags", platform_data["hashtags"]),
            "seo_strategy": youtube_data.get("seo_strategy", platform_data["seo_strategy"]),
            "youtube_metadata": youtube_data.get("youtube_metadata", platform_data["video_metadata"]),
            "api_ready_format": platform_data["api_ready_format"]
        }
        with open(youtube_path, "w", encoding="utf-8") as f:
            json.dump(youtube_metadata, f, indent=2, ensure_ascii=False)
        saved_files.append("youtube_metadata.json")

        # 9. Thumbnail data with composition strategy
        thumbnail_data = result.get("thumbnail_data", {})
        if thumbnail_data.get("thumbnail_prompt"):
            thumbnail_path = output_path / "thumbnail_generation.json"
            with open(thumbnail_path, "w", encoding="utf-8") as f:
                json.dump(thumbnail_data, f, indent=2, ensure_ascii=False)
            saved_files.append("thumbnail_generation.json")

        # 10. Hook & Subscribe scenes
        hook_subscribe_data = result.get("hook_subscribe_scenes", {})
        if hook_subscribe_data:
            hook_subscribe_path = output_path / "hook_subscribe_scenes.json"
            with open(hook_subscribe_path, "w", encoding="utf-8") as f:
                json.dump(hook_subscribe_data, f, indent=2, ensure_ascii=False)
            saved_files.append("hook_subscribe_scenes.json")

        # 11. Production specifications
        production_specs = result.get("production_specifications", {})
        if production_specs:
            production_path = output_path / "production_specifications.json"
            with open(production_path, "w", encoding="utf-8") as f:
                json.dump(production_specs, f, indent=2, ensure_ascii=False)
            saved_files.append("production_specifications.json")

        # 12. AUTOMATION_SPECS.JSON
        automation_path = output_path / "automation_specs.json"
        automation_data = {
            "audio_production": production_specs.get("audio_production", {}),
            "video_assembly": production_specs.get("video_assembly", {}),
            "quality_control": production_specs.get("quality_control", {}),
            "automation_specifications": production_specs.get("automation_specifications", {}),
            "precise_timing_breakdown": production_specs.get("precise_timing_breakdown", {}),
            "validation_system": {
                "enabled": result.get("generation_stats", {}).get("validation_system_enabled", False),
                "stories_corrected": result.get("generation_stats", {}).get("stories_corrected", 0),
                "validation_tolerance": CONFIG.claude_config.get('target_tolerance', 0.2)
            },
            "implementation_ready": True
        }
        with open(automation_path, "w", encoding="utf-8") as f:
            json.dump(automation_data, f, indent=2, ensure_ascii=False)
        saved_files.append("automation_specs.json")

        # 13. Audio generation prompts
        audio_prompts = []

        # Hook audio
        hook_section = result.get("hook_section", {})
        if hook_section:
            audio_prompts.append({
                "segment_id": "hook",
                "content": hook_section.get("content", ""),
                "duration_seconds": hook_section.get("duration_seconds", 30),
                "voice_direction": hook_section.get("voice_direction", ""),
                "tts_settings": {
                    "voice": "alloy",
                    "speed": 0.9,
                    "pitch": "normal",
                    "emphasis": "gentle mystery"
                }
            })

        # Subscribe audio
        subscribe_section = result.get("subscribe_section", {})
        if subscribe_section:
            audio_prompts.append({
                "segment_id": "subscribe",
                "content": subscribe_section.get("content", ""),
                "duration_seconds": subscribe_section.get("duration_seconds", 30),
                "voice_direction": subscribe_section.get("voice_direction", ""),
                "tts_settings": {
                    "voice": "alloy",
                    "speed": 0.95,
                    "pitch": "warm",
                    "emphasis": "friendly conversation"
                }
            })

        # Story scenes audio with production specs
        stories = result.get("stories", {})
        voice_directions = result.get("voice_directions", [])
        production_audio = production_specs.get("audio_production", {})
        tts_settings = production_audio.get("tts_settings", {})

        for scene_id, story_content in stories.items():
            voice_direction = next((v for v in voice_directions if v.get("scene_number") == int(scene_id)), {})
            scene_info = next((s for s in result.get("scene_plan", []) if s.get("scene_id") == int(scene_id)), {})

            audio_prompts.append({
                "segment_id": f"scene_{scene_id}",
                "content": story_content,
                "duration_minutes": scene_info.get("duration_minutes", 4),
                "voice_direction": voice_direction.get("direction", ""),
                "template": voice_direction.get("template", "atmospheric"),
                "style": voice_direction.get("style", "observational"),
                "emotion": scene_info.get("emotion", "peaceful"),
                "tts_settings": {
                    "voice": tts_settings.get("optimal_voice", "alloy"),
                    "speed": tts_settings.get("speed_multiplier", 0.85),
                    "pitch": tts_settings.get("pitch_adjustment", -2),
                    "volume": tts_settings.get("volume_level", 80),
                    "emphasis": "sleep-optimized"
                }
            })

        audio_path = output_path / "audio_generation_prompts.json"
        with open(audio_path, "w", encoding="utf-8") as f:
            json.dump(audio_prompts, f, indent=2, ensure_ascii=False)
        saved_files.append("audio_generation_prompts.json")

        # 14. ALL_STORIES.JSON (validated stories)
        stories_path = output_path / "all_stories.json"
        with open(stories_path, "w", encoding="utf-8") as f:
            json.dump(result["stories"], f, indent=2, ensure_ascii=False)
        saved_files.append("all_stories.json")

        # 15. Video composition instructions
        production_video = production_specs.get("video_assembly", {})
        video_specs = production_video.get("video_specifications", {})

        video_composition = {
            "timeline_structure": [
                {
                    "segment": "hook",
                    "start_time": 0,
                    "end_time": 30,
                    "video_source": "hook_subscribe_scenes.json -> hook_scenes",
                    "audio_source": "audio_generation_prompts.json -> hook segment",
                    "text_overlay": "None (pure atmospheric)",
                    "transition": "fade_in"
                },
                {
                    "segment": "subscribe",
                    "start_time": 30,
                    "end_time": 60,
                    "video_source": "hook_subscribe_scenes.json -> subscribe_scenes",
                    "audio_source": "audio_generation_prompts.json -> subscribe segment",
                    "text_overlay": "Subscribe button animation",
                    "transition": "smooth_blend"
                },
                {
                    "segment": "main_story",
                    "start_time": 60,
                    "end_time": sum(
                        scene.get('duration_minutes', 4) * 60 for scene in result.get("scene_plan", [])) + 60,
                    "video_source": "visual_generation_prompts.json -> scenes 1-N",
                    "audio_source": "audio_generation_prompts.json -> scenes 1-N",
                    "text_overlay": "Scene titles (optional)",
                    "transition": "crossfade_between_scenes"
                }
            ],
            "scene_sync_strategy": {
                "rule": "When audio mentions scene X, display scene X visual",
                "timing": "Immediate visual sync with narrative",
                "duration": "Variable scene durations from smart algorithm",
                "overlap": "15 second crossfade between scenes"
            },
            "thumbnail_usage": {
                "source": "visual_generation_prompts.json -> scene 99",
                "purpose": "YouTube thumbnail only, not used in video timeline",
                "composition": "RIGHT-side character, LEFT-side text overlay space"
            },
            "production_settings": {
                "resolution": video_specs.get("resolution", "1920x1080"),
                "frame_rate": video_specs.get("frame_rate", 30),
                "audio_bitrate": 192,
                "video_codec": "h264",
                "total_duration": f"{sum(scene.get('duration_minutes', 4) for scene in result.get('scene_plan', [])) + 1} minutes"
            },
            "chapters": result.get("scene_chapters", []),
            "validation_notes": {
                "stories_validated": result.get("generation_stats", {}).get("validation_system_enabled", False),
                "stories_corrected": result.get("generation_stats", {}).get("stories_corrected", 0),
                "duration_accuracy": "Enhanced with validation system"
            }
        }

        video_path = output_path / "video_composition_instructions.json"
        with open(video_path, "w", encoding="utf-8") as f:
            json.dump(video_composition, f, indent=2, ensure_ascii=False)
        saved_files.append("video_composition_instructions.json")

        # 16. Generation report (COMPREHENSIVE WITH VALIDATION)
        report_path = output_path / "generation_report.json"
        production_report = {
            "topic": story_topic,
            "topic_id": topic_id,
            "generation_completed": datetime.now().isoformat(),
            "model_used": CONFIG.claude_config["model"],
            "claude_4_optimized": True,
            "server_optimized": True,
            "five_stage_approach": True,
            "smart_algorithm_used": result.get("generation_stats", {}).get("smart_algorithm", False),
            "validation_system_enabled": result.get("generation_stats", {}).get("validation_system_enabled", False),
            "all_local_features_integrated": result.get("generation_stats", {}).get("all_local_features_integrated", False),
            "complete_pipeline": True,
            "stats": result["generation_stats"],
            "cost_analysis": {
                "total_api_calls": api_calls,
                "total_cost": total_cost,
                "cost_per_scene": total_cost / len(result.get("scene_plan", [1])),
                "cost_efficiency": "Claude 4 optimized with validation system"
            },
            "quality_metrics": {
                "scenes_planned": len(result.get("scene_plan", [])),
                "stories_written": len(result.get("stories", {})),
                "characters_extracted": len(result.get("main_characters", [])),
                "completion_rate": (len(result.get("stories", {})) / len(result.get("scene_plan", [1]))) * 100,
                "youtube_optimization": bool(result.get("youtube_optimization", {}).get("clickbait_titles")),
                "production_specs": bool(result.get("production_specifications", {}).get("audio_production")),
                "thumbnail_composition": bool(result.get("thumbnail_data", {}).get("thumbnail_prompt")),
                "platform_metadata_complete": True,
                "hook_subscribe_generated": bool(result.get("hook_subscribe_scenes", {}).get("hook_scenes")),
                "validation_system_used": result.get("generation_stats", {}).get("validation_system_enabled", False),
                "stories_validated": result.get("generation_stats", {}).get("stories_validated", 0),
                "stories_corrected": result.get("generation_stats", {}).get("stories_corrected", 0)
            },
            "validation_summary": {
                "enabled": result.get("generation_stats", {}).get("validation_system_enabled", False),
                "stories_corrected": result.get("generation_stats", {}).get("stories_corrected", 0),
                "target_tolerance": CONFIG.claude_config.get('target_tolerance', 0.2),
                "auto_correction": CONFIG.claude_config.get('auto_correction', True),
                "validation_log_entries": len(result.get("validation_log", []))
            },
            "files_saved": saved_files,
            "next_steps": [
                "1. Generate character reference images using character_profiles.json",
                "2. Generate scene visuals (1-N) using visual_generation_prompts.json",
                "3. Generate thumbnail (scene 99) using visual_generation_prompts.json",
                "4. Generate audio using audio_generation_prompts.json with production specifications",
                "5. Compose video using video_composition_instructions.json with chapters",
                "6. Upload to YouTube using platform_metadata.json with full SEO optimization",
                "7. Review validation_report.json for quality assurance"
            ],
            "automation_readiness": {
                "character_extraction": "‚úÖ Complete",
                "youtube_optimization": "‚úÖ Complete",
                "production_specifications": "‚úÖ Complete",
                "platform_metadata": "‚úÖ Complete",
                "composition_strategy": "‚úÖ Complete",
                "api_ready_format": "‚úÖ Complete",
                "all_local_features": "‚úÖ Complete",
                "validation_system": "‚úÖ Complete with auto-correction"
            }
        }
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(production_report, f, indent=2, ensure_ascii=False)
        saved_files.append("generation_report.json")

        print(f"‚úÖ Complete production files saved ({len(saved_files)} TOTAL - ALL LOCAL + SERVER FEATURES + VALIDATION): {saved_files}")
        CONFIG.logger.info(f"Files saved to: {output_dir}")

        # Mark topic as completed in database
        scene_count = len(result.get('scene_plan', []))
        total_duration = sum(scene.get('duration_minutes', 4) for scene in result.get('scene_plan', []))

        complete_topic_in_database(
            topic_id, scene_count, total_duration, api_calls, total_cost, output_dir
        )

    except Exception as e:
        print(f"‚ùå Save error: {e}")
        CONFIG.logger.error(f"Save error: {e}")


def print_production_summary(result: Dict, story_topic: str, output_path: str, generation_time: float):
    """Print complete production generation summary with validation system features"""
    stats = result["generation_stats"]

    print("\n" + "üöÄ" * 60)
    print("COMPLETE AUTOMATED STORY GENERATOR WITH VALIDATION SYSTEM!")
    print("üöÄ" * 60)

    print(f"üìö Topic: {story_topic}")
    print(f"üìÅ Output: {output_path}")
    print(f"ü§ñ Model: {CONFIG.claude_config['model']} (Claude 4)")
    print(f"üñ•Ô∏è  Server Mode: {'‚úÖ ACTIVE' if stats.get('server_optimized') else '‚ùå OFF'}")
    print(f"üè≠ Complete Pipeline: {'‚úÖ ACTIVE' if stats.get('complete_pipeline') else '‚ùå OFF'}")
    print(f"üé≤ Smart Algorithm: {'‚úÖ ACTIVE' if stats.get('smart_algorithm') else '‚ùå OFF'}")
    print(f"üéØ 5-Stage Approach: {'‚úÖ ACTIVE' if stats.get('five_stage_approach') else '‚ùå OFF'}")
    print(f"üîó All Local Features: {'‚úÖ INTEGRATED' if stats.get('all_local_features_integrated') else '‚ùå MISSING'}")
    print(f"üõ°Ô∏è  Validation System: {'‚úÖ ACTIVE' if stats.get('validation_system_enabled') else '‚ùå OFF'}")
    print(f"üîß Auto-Correction: {'‚úÖ ACTIVE' if stats.get('auto_correction_enabled') else '‚ùå OFF'}")

    print(f"\nüìä CLAUDE 4 + VALIDATION PERFORMANCE:")
    print(f"üî• Total API Calls: {stats['api_calls_used']}")
    print(f"üí∞ Total Cost: ${result.get('total_cost', 0):.4f}")
    print(f"‚è±Ô∏è  Total Generation Time: {generation_time:.1f}s")
    print(f"üé¨ Scenes Planned: {stats['scenes_planned']}")
    print(f"üìù Stories Written: {stats['stories_written']}")
    print(f"‚úÖ Stories Validated: {stats.get('stories_validated', 'N/A')}")
    print(f"üîß Stories Corrected: {stats.get('stories_corrected', 0)}")
    print(f"üë• Characters Extracted: {stats['characters_extracted']}")
    print(f"üñºÔ∏è  Thumbnail Generated: {'‚úÖ YES' if stats.get('thumbnail_generated') else '‚ùå NO'}")
    print(f"üì∫ YouTube Optimization: {'‚úÖ YES' if stats.get('youtube_optimization_generated') else '‚ùå NO'}")
    print(f"üè≠ Production Specs: {'‚úÖ YES' if stats.get('production_specifications_generated') else '‚ùå NO'}")
    print(f"üé≠ Hook & Subscribe: {'‚úÖ YES' if stats.get('hook_subscribe_generated') else '‚ùå NO'}")
    print(f"üé• Visual Prompts (with thumbnail): {stats.get('visual_prompts_with_thumbnail', 0)}")

    # Validation system stats
    if stats.get('validation_system_enabled'):
        print(f"\nüõ°Ô∏è  VALIDATION SYSTEM RESULTS:")
        validation_report = result.get('validation_report', {})
        print(f"üìä Target Tolerance: ¬±{CONFIG.claude_config.get('target_tolerance', 0.2)*100:.0f}%")
        print(f"üìè Words per Minute: {CONFIG.claude_config.get('target_words_per_minute', 140)}")
        print(f"‚úÖ Stories Validated: {stats.get('stories_validated', 0)}")
        print(f"üîß Stories Auto-Corrected: {stats.get('stories_corrected', 0)}")
        if stats.get('stories_corrected', 0) > 0:
            print(f"üí° Duration accuracy improved through auto-correction!")
        print(f"üìã Validation Log Entries: {len(result.get('validation_log', []))}")

    # Smart generation stats
    if stats.get('smart_algorithm'):
        print(f"\nüé≤ SMART GENERATION STATS:")
        print(f"üìä Random Scene Count: {stats.get('random_scene_count', 'N/A')}")
        print(f"‚è±Ô∏è  Duration Range: {stats.get('duration_range', 'N/A')}")
        print(f"üåü Natural Variation: {'‚úÖ YES' if stats.get('natural_duration_variation') else '‚ùå NO'}")

        # Calculate scene statistics
        scene_plan = result.get('scene_plan', [])
        if scene_plan:
            durations = [scene.get('duration_minutes', 4) for scene in scene_plan]
            total_duration = sum(durations)
            print(f"üìà Total Duration: {total_duration:.1f} minutes ({total_duration / 60:.1f} hours)")
            print(f"üìä Average Scene: {total_duration / len(durations):.1f} minutes")
            print(f"üéØ Duration Accuracy: Smart algorithm + validation system ensures precision")

    # Character analysis
    characters = result.get("main_characters", [])
    if characters:
        print(f"\nüë• MAIN CHARACTERS:")
        for char in characters:
            print(
                f"‚Ä¢ {char.get('name', 'Unknown')} ({char.get('role', 'unknown role')}) - Score: {char.get('importance_score', 0)}/10")

    completion_rate = (stats['stories_written'] / stats.get('scenes_planned', 1)) * 100
    print(f"\nüìä Story Completion: {completion_rate:.1f}%")

    if completion_rate >= 80:
        print(f"\nüéâ MASSIVE SUCCESS WITH VALIDATION!")
        print(f"‚úÖ Complete story + character + YouTube + production + thumbnail + validation system")
        print(f"‚úÖ ALL LOCAL FEATURES + VALIDATION SYSTEM INTEGRATED!")
        print(f"‚úÖ Ready for FULL AUTOMATION with quality assurance")
        print(f"üöÄ Zero manual work needed with automatic error correction!")
    elif completion_rate >= 60:
        print(f"\n‚úÖ EXCELLENT PROGRESS WITH VALIDATION!")
        print(f"‚ö° Ready for automated pipeline with quality assurance")
        print(f"üéØ Production deployment recommended with validation")
    else:
        print(f"\n‚ö†Ô∏è PARTIAL SUCCESS")
        print(f"üîç Review generation_report.json and validation_report.json for issues")

    print(f"\nüìÑ GENERATED FILES ({len(saved_files if 'saved_files' in locals() else [])} TOTAL - ALL FEATURES + VALIDATION):")
    print("1. üìñ complete_story.txt - Full story text (validated)")
    print("2. üé¨ scene_plan.json - Smart scene structure + chapters")
    print("3. üñºÔ∏è  visual_generation_prompts.json - Scenes + Thumbnail (99)")
    print("4. üéµ voice_directions.json - TTS guidance")
    print("5. üë• character_profiles.json - Character data with generation instructions")
    print("6. üõ°Ô∏è  validation_report.json - Validation system results (NEW)")
    print("7. üåç platform_metadata.json - COMPREHENSIVE platform data + API ready format")
    print("8. üì∫ youtube_metadata.json - YouTube-specific metadata (compatibility)")
    print("9. üñºÔ∏è  thumbnail_generation.json - Thumbnail composition strategy")
    print("10. üé≠ hook_subscribe_scenes.json - Background scenes for opening")
    print("11. üè≠ production_specifications.json - Complete production specs")
    print("12. ü§ñ automation_specs.json - Automation-specific data with validation")
    print("13. üéµ audio_generation_prompts.json - Enhanced TTS production")
    print("14. üìö all_stories.json - All validated stories in separate file")
    print("15. üé• video_composition_instructions.json - Video timeline + chapters")
    print("16. üìä generation_report.json - Complete summary with validation metrics")

    print(f"\nüÜï VALIDATION SYSTEM ADVANTAGES:")
    print(f"‚úÖ Automatic story duration validation")
    print(f"‚úÖ Auto-correction for stories that are too short/long")
    print(f"‚úÖ Target word count precision (¬±{CONFIG.claude_config.get('target_tolerance', 0.2)*100:.0f}% tolerance)")
    print(f"‚úÖ Missing story generation for incomplete scenes")
    print(f"‚úÖ Quality assurance with detailed validation logs")
    print(f"‚úÖ Consistent duration targeting for TTS optimization")
    print(f"‚úÖ Automatic retry and correction system")
    print(f"‚úÖ Budget-aware correction limiting")

    print(f"\nüí∞ EFFICIENCY vs MANUAL WORK WITH VALIDATION:")
    print(f"üíµ Cost: 5-7 API calls vs manual story editing + duration checking")
    print(f"‚ö° Speed: Automatic validation + correction + character extraction + platform optimization")
    print(f"üîß Consistency: Built-in quality control + duration validation + character mapping")
    print(f"üéØ Scalability: Works for any story topic with automatic quality assurance")
    print(f"üõ°Ô∏è  Reliability: Validation system ensures consistent output quality")

    print(f"\nüèÜ COMPLETE AUTOMATION ADVANTAGES (ALL FEATURES + VALIDATION):")
    print("‚úÖ Dynamic character extraction for any topic")
    print("‚úÖ Automatic consistency mapping")
    print("‚úÖ Visual generation pipeline ready")
    print("‚úÖ FIXED: Visual prompts match scene content exactly")
    print("‚úÖ Character-scene mapping for perfect consistency")
    print("‚úÖ INTELLIGENT THUMBNAIL GENERATION")
    print("‚úÖ Character analysis for optimal thumbnail selection")
    print("‚úÖ Clickbait optimization while maintaining sleep content feel")
    print("‚úÖ COMPREHENSIVE PLATFORM OPTIMIZATION")
    print("‚úÖ Enhanced API-ready formats for all platforms")
    print("‚úÖ Complete audio production specs with TTS optimization")
    print("‚úÖ Video assembly automation with precise timing")
    print("‚úÖ Quality control validation with smart algorithm")
    print("‚úÖ Batch processing automation with database management")
    print("‚úÖ Precise timing calculations with natural variation")
    print("‚úÖ üÜï AUTOMATIC STORY VALIDATION AND CORRECTION")
    print("‚úÖ üÜï DURATION ACCURACY ASSURANCE")
    print("‚úÖ üÜï MISSING STORY AUTO-GENERATION")
    print("‚úÖ üÜï QUALITY METRICS AND REPORTING")
    print("‚úÖ Zero manual work needed - 16 complete files with validation")
    print("‚úÖ Scalable to unlimited stories with quality assurance")
    print("‚úÖ FULL END-TO-END AUTOMATION WITH VALIDATION SYSTEM")

    print("üöÄ" * 60)


def run_autonomous_mode():
    """Run autonomous mode with validation system - continuously process pending topics"""
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent / 'database'))
    from autonomous_database_manager import AutonomousDatabaseManager
    import signal

    print("ü§ñ AUTONOMOUS MODE WITH VALIDATION SYSTEM STARTED")
    print("üîÑ Will process all pending topics continuously")
    print("üõ°Ô∏è  Validation system enabled for quality assurance")
    print("‚èπÔ∏è Press Ctrl+C to stop gracefully")

    # Initialize database manager
    db_manager = AutonomousDatabaseManager()

    # Setup graceful shutdown
    running = True
    processed_count = 0
    start_time = time.time()

    def signal_handler(signum, frame):
        nonlocal running
        print(f"\n‚èπÔ∏è Received shutdown signal ({signum})")
        print("üîÑ Finishing current topic and shutting down...")
        running = False

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    while running:
        try:
            # Get next topic ready for story generation
            next_topic = db_manager.get_next_story_generation_topic()

            if next_topic:
                topic_id, topic, description = next_topic
                clickbait_title = ""
                font_design = ""

                print(f"\nüîÑ Processing topic {topic_id}: {topic}")
                print(f"üõ°Ô∏è  Validation system will ensure quality")

                # Mark as started
                db_manager.mark_story_generation_started(topic_id)
                try:
                    # Setup output directory
                    output_path = Path(CONFIG.paths['OUTPUT_DIR']) / str(topic_id)

                    # Initialize generator with validation
                    generator = AutomatedStoryGenerator()

                    # Generate complete story with validation
                    start_gen_time = time.time()
                    result = generator.generate_complete_story_with_characters(
                        topic, description, clickbait_title, font_design
                    )
                    generation_time = time.time() - start_gen_time

                    # Add total cost
                    result['total_cost'] = generator.total_cost

                    # Save all production outputs (ALL 16 FILES WITH VALIDATION)
                    save_production_outputs(
                        str(output_path), result, topic, topic_id,
                        generator.api_call_count, generator.total_cost
                    )

                    # Print summary with validation stats
                    print_production_summary(result, topic, str(output_path), generation_time)

                    processed_count += 1
                    print(f"\n‚úÖ Topic {topic_id} completed successfully with validation!")
                    print(f"üìä Progress: {processed_count} topics processed")

                    # Show validation summary
                    if result.get('generation_stats', {}).get('validation_system_enabled'):
                        stories_corrected = result.get('generation_stats', {}).get('stories_corrected', 0)
                        if stories_corrected > 0:
                            print(f"üõ°Ô∏è  Validation System: {stories_corrected} stories auto-corrected for optimal duration")

                except Exception as e:
                    print(f"‚ùå Error processing topic {topic_id}: {e}")
                    db_manager.mark_story_generation_failed(topic_id, str(e))
                    import traceback
                    traceback.print_exc()

                # Short pause between topics
                if running:
                    time.sleep(5)

            else:
                # No topics ready, wait
                print("üò¥ No topics ready for processing. Waiting 60s...")
                for i in range(60):
                    if not running:
                        break
                    time.sleep(1)

        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Keyboard interrupt received")
            break
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
            time.sleep(30)

    # Shutdown summary
    runtime = time.time() - start_time
    print(f"\nüèÅ AUTONOMOUS MODE WITH VALIDATION SHUTDOWN")
    print(f"‚è±Ô∏è Total runtime: {runtime / 3600:.1f} hours")
    print(f"‚úÖ Topics processed: {processed_count}")
    print(f"üõ°Ô∏è  Validation system ensured quality throughout")
    print("üëã Goodbye!")


if __name__ == "__main__":
    # Check for autonomous mode
    if len(sys.argv) > 1 and sys.argv[1] == '--autonomous':
        run_autonomous_mode()
    else:
        # Original single topic mode with validation
        try:
            print("üöÄ COMPLETE AUTOMATED STORY GENERATOR WITH VALIDATION SYSTEM")
            print("‚ö° Server-optimized with complete pipeline + ALL local features + VALIDATION")
            print("üé≤ FIXED: Smart random scene count & duration generation")
            print("üìä FIXED: Database integration instead of CSV")
            print("üé≠ 5-stage approach: Planning + Stories + VALIDATION + Characters + Thumbnail + Hook/Subscribe")
            print("üõ°Ô∏è  NEW: Automatic story validation and correction system")
            print("üîß NEW: Auto-correction for duration accuracy")
            print("üìÑ Complete JSON outputs for automation (16 files)")
            print("üéØ RIGHT-side thumbnail positioning for text overlay")
            print("‚úÖ INTEGRATED: All local features + Enhanced server features + Validation system")
            print("üåç COMPREHENSIVE: platform_metadata.json + youtube_metadata.json + validation_report.json")
            print("=" * 60)

            # Get next topic from database
            topic_id, topic, description, clickbait_title, font_design = get_next_topic_from_database()
            print(f"\nüìö Topic ID: {topic_id} - {topic}")
            print(f"üìù Description: {description}")
            if clickbait_title:
                print(f"üéØ Clickbait Title: {clickbait_title}")

            # Setup output directory
            output_path = Path(CONFIG.paths['OUTPUT_DIR']) / str(topic_id)

            # Initialize generator with validation
            generator = AutomatedStoryGenerator()

            # Generate complete story with ALL LOCAL + SERVER FEATURES + VALIDATION
            start_time = time.time()
            result = generator.generate_complete_story_with_characters(
                topic, description, clickbait_title, font_design
            )
            generation_time = time.time() - start_time

            # Add total cost to result
            result['total_cost'] = generator.total_cost

            # Save outputs with ALL LOCAL + SERVER FEATURES + VALIDATION
            save_production_outputs(str(output_path), result, topic, topic_id,
                                    generator.api_call_count, generator.total_cost)

            # Print comprehensive summary with validation
            print_production_summary(result, topic, str(output_path), generation_time)

            print("\nüöÄ COMPLETE PRODUCTION PIPELINE WITH VALIDATION FINISHED!")
            print(f"‚úÖ All files ready for: {output_path}")
            print(f"üìä Database topic management: WORKING")
            print(f"üé≤ Smart algorithm scene generation: FIXED")
            print(f"üìù Story distribution: FIXED")
            print(f"üõ°Ô∏è  Story validation system: ADDED")
            print(f"üîß Auto-correction system: ADDED")
            print(f"üìö all_stories.json: VALIDATED")
            print(f"ü§ñ automation_specs.json: ENHANCED WITH VALIDATION")
            print(f"üåç platform_metadata.json: COMPREHENSIVE")
            print(f"üîå api_ready_format: ENHANCED")
            print(f"üé≠ character extraction: ADVANCED")
            print(f"üñºÔ∏è  thumbnail generation: INTELLIGENT")
            print(f"üé¨ video composition: AUTOMATED")
            print(f"üìã validation_report.json: QUALITY ASSURANCE")
            print(f"üí∞ Total cost: ${result.get('total_cost', 0):.4f}")

            # Show validation results
            if result.get('generation_stats', {}).get('validation_system_enabled'):
                stories_corrected = result.get('generation_stats', {}).get('stories_corrected', 0)
                stories_validated = result.get('generation_stats', {}).get('stories_validated', 0)
                print(f"üõ°Ô∏è  Validation Results: {stories_validated} stories validated, {stories_corrected} auto-corrected")

            print(f"üèÜ SUCCESS: All local features + validation system integrated into server version!")

        except Exception as e:
            print(f"\nüí• COMPLETE GENERATOR ERROR: {e}")
            CONFIG.logger.error(f"Generation failed: {e}")
            import traceback
            traceback.print_exc()